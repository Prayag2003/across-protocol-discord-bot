{
    "https://docs.across.to/developer-docs": {
        "title": "Overview | Across Docs",
        "headers": [
            "Overview"
        ],
        "paragraphs": [
            "Below is an overview of how a bridge transfer on Across works from start to finish.",
            "Last updated 11 months ago",
            "A user that would like to move funds from chain A to chain B deposits funds into a Spoke Pool on chain A with instructions about where they would like their funds to wind up and the fee that they are willing to pay.",
            "After the relayer has performed the relay, a proof of that relay and the validity of the original deposit is submitted to the optimistic oracle (OO) and the relayer is reimbursed once this information has been verified by the OO.",
            "The relayer's reimbursement is taken out of a single liquidity pool on Ethereum Mainnet escrowed in a contract called the Hub Pool. Liquidity providers (\"LP's\") to this pool also earn a fee per transfer that is assessed on the user's deposited amount.",
            "The rules for how funds are moved between the L2 Spoke Pools and the L1 Hub Pool to reimburse relayers are explained in UMIP-157. Anyone who wants to move funds between the pools must submit a valid proof to the OO that abides by the rules explained in the UMIP.",
            "To see how this all comes together, check out the chart below showing a complete end-to-end flow of the process.",
            "The smart contract code can be found here, including implementations of the HubPool and SpokePool.",
            "The smart contracts were audited by OpenZeppelin. The audit report contains a high-level summary of how the smart contract architecture works.",
            "Moreover, here is a 60-minute explainer video of the smart contract architecture. Slides for the explainer video can be found here."
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/?fallback=true": {
        "title": "Getting Started | Across Docs",
        "headers": [
            "Looking for something else? Get in touch"
        ],
        "paragraphs": [
            "Across is an interoperability protocol powered by intents. It is the first cross-chain intents protocol in production today, enabling the fastest and lowest-cost way to transfer value with better security tradeoffs vs. traditional bridge designs. ",
            "Across can be easily integrated via our easy to use REST API into any application requiring instant, low cost cross-chain value transfer. Let users easily onboard assets without leaving your app. ",
            "Across can also be integrated in your application to abstract bridging completely, enabling users to directly interact with your app from any chain. ",
            "Across Settlement is the only production-ready, modular settlement layer built to facilitate cross-chain intents. Powers use cases that require customization beyond the Across Core offering, like cross-chain token swaps, new request for quote auction designs and more. ",
            "Join the growing network of independent relayers (a.k.a solvers, fillers, market makers) fulfilling intent order flow on Across. Earn up to 100% APY. ",
            "",
            "Last updated 1 month ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs?fallback=true": {
        "title": "Overview | Across Docs",
        "headers": [
            "Overview"
        ],
        "paragraphs": [
            "Below is an overview of how a bridge transfer on Across works from start to finish.",
            "Last updated 11 months ago",
            "A user that would like to move funds from chain A to chain B deposits funds into a Spoke Pool on chain A with instructions about where they would like their funds to wind up and the fee that they are willing to pay.",
            "After the relayer has performed the relay, a proof of that relay and the validity of the original deposit is submitted to the optimistic oracle (OO) and the relayer is reimbursed once this information has been verified by the OO.",
            "The relayer's reimbursement is taken out of a single liquidity pool on Ethereum Mainnet escrowed in a contract called the Hub Pool. Liquidity providers (\"LP's\") to this pool also earn a fee per transfer that is assessed on the user's deposited amount.",
            "The rules for how funds are moved between the L2 Spoke Pools and the L1 Hub Pool to reimburse relayers are explained in UMIP-157. Anyone who wants to move funds between the pools must submit a valid proof to the OO that abides by the rules explained in the UMIP.",
            "To see how this all comes together, check out the chart below showing a complete end-to-end flow of the process.",
            "The smart contract code can be found here, including implementations of the HubPool and SpokePool.",
            "The smart contracts were audited by OpenZeppelin. The audit report contains a high-level summary of how the smart contract architecture works.",
            "Moreover, here is a 60-minute explainer video of the smart contract architecture. Slides for the explainer video can be found here."
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/user-docs?fallback=true": {
        "title": "About | Across Docs",
        "headers": [
            "About"
        ],
        "paragraphs": [
            "Interoperability Powered by Intents",
            "Across is an interoperability protocol powered by intents. It is the only cross-chain intents protocol in production today, enabling the fastest and lowest-cost interoperability solution without security tradeoffs.\n\nAcross Protocol is comprised of three products.",
            "The Across Bridge, the most capital efficient cross-chain transfer solution for end users. Across' intents-based framework has proven to facilitate the fastest and cheapest bridging between L2s and Mainnet.",
            "Across+, is a chain abstraction tool that utilizes cross-chain bridge hooks to fulfill user intents. Across+ allows developers to integrate bridge + action(s) bundles at the dapp level to promote onboarding and abstract the bridging process away from end users.",
            "Across Settlement, is a settlement layer for all cross-chain intent order flow. Its optimistic design, which defers verification, focuses on gas optimization to significantly reduce cross-chain settlement costs for protocols and, ultimately, end users.",
            "As the multichain economy continues to evolve, intents-based settlement is the key to solving interoperability and Across is at the core of its execution.",
            "Last updated 9 months ago"
        ],
        "lists": [
            "About\nBridging\nProviding Bridge Liquidity\nProtocol Rewards\nReward Locking\nTransaction History",
            "Reward Locking",
            "Token Overview\nInitial Allocations\nACX Emissions Committee",
            "Governance Model\nProposals and Voting",
            "FAQ\nSupport Links\nMigrating from V1\nAcross Brand Assets"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/how-across-works/readme/roles-within-across": {
        "title": "Roles within Across | Across Docs",
        "headers": [
            "Roles within Across",
            "User",
            "Liquidity Provider",
            "Relayer ",
            "Dataworker"
        ],
        "paragraphs": [
            "Describing key roles within the Across system.",
            "A user is someone who bridges assets between L2s and L1 with Across. Users pay relayers and liquidity providers in order to send their tokens instantly across networks that support their token. You can find the step by step for users here. ",
            "A liquidity provider or LP is an actor who deposits assets into one of the pools on Across.to/pool. Liquidity Providers insure user funds in exchange for fees. You can find the step-by-step process for liquidity providers here. ",
            "Dataworkers support the stability and healthy functioning of the system by refunding relayers and moving system assets between networks.",
            "",
            "Last updated 1 year ago"
        ],
        "lists": [
            "User\nLiquidity Provider\nRelayer \nDataworker"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/how-across-works/readme/fee-model": {
        "title": "Fee Model | Across Docs",
        "headers": [
            "Fee Model",
            "Liquidity Provider Fees",
            "Relayer Fees"
        ],
        "paragraphs": [
            "We view using Across as being similar to lending protocols such as AAVE or Compound. When a user bridges a particular token from one chain to another, the fast bridge isn't \"moving tokens from one chain to another\" but, rather, it is a relayer or the protocol itself providing tokens on the destination chain in return for tokens on the origin chain. We choose to use a similar pricing model for our liquidity provider fees because of this parallel.",
            "We base our pricing model on the one described in AAVE's documentation. Let,",
            "XXXdenote the size of a particular transaction someone is seeking to bridge",
            "0≤Ut≤10 \\leq U_t \\leq 10≤Ut​≤1denote the utilization of the liquidity providers' capital prior to the transaction, i.e. the amount of the liquidity providers' capital that is in use prior to the current transaction",
            "0≤U^t≤10 \\leq \\hat{U}_t \\leq 10≤U^t​≤1denote the utilization of the liquidity providers' capital after to the transaction, i.e. the amount of the liquidity providers' capital that would be in use if the user chose to execute their transaction",
            "Uˉ\\bar{U}Uˉdenote the \"kink utilization\" where the slope on the interest rate changes",
            "R0,R1,R2R_0, R_1, R_2R0​,R1​,R2​denote the parameters governing the interest rate model slopes",
            "R0R_0R0​is the interest rate that would be charged at 0% utilization",
            "R0+R1R_0 + R_1R0​+R1​is the interest rate that would be charged at Uˉ%\\bar{U}\\% Uˉ%utilization",
            "R0+R1+R2R_0 + R_1 + R_2R0​+R1​+R2​is the interest rate that would be charged at 100% utilization",
            "The (annualized) interest rate model is then defined by",
            "We calculate the (annualized) interest rate for a particular loan by aggregating the marginal increases of utilization by integrating over this function",
            "The actual fee that is charged will be based on making a loan at this rate for a 1 week time-span. The rate that is charged can be computed from:",
            "and the fee would be",
            "",
            "This might seem like a lot that you are required to understand, but when you are interacting with the bridge, these details will mostly be hidden from you and you will just see a value for the \"liquidity provider fee\".",
            "We chose to charge prices this way to ensure that users are paying a \"fair\" price for the amount of utilization that their bridge transaction incurs.",
            "Relayer fees play a similar role in the Across ecosystem as gas fees play in the Ethereum ecosystem. Relayer fees are a fee that the user sets to incentivize relayers to relay your bridge transaction.",
            "Relaying a transaction has three costs for relayers:",
            "Gas fees: The relayer pays gas to perform the relay and to claim their repayment.",
            "Capital opportunity costs: The fact that the relayer is using their capital to perform a relay means that they are not using it for other yield opportunities.",
            "Capital at risk: A relayer takes on certain risks by relaying funds. If they make a mistake when relaying that could jeopardize their repayment of the capital they invested.",
            "These fees are automatically set by the front-end but could also be set manually by interacting with the contract directly. If you set them manually, make sure to set them high enough so that a relayer would be willing to relay your transactions.",
            "",
            "",
            "Last updated 1 year ago"
        ],
        "lists": [
            "Liquidity Provider Fees\nRelayer Fees",
            "X\nX\nX\ndenote the size of a particular transaction someone is seeking to bridge\n0\n≤\nU\nt\n≤\n1\n0 \\leq U_t \\leq 1\n0\n≤\nU\nt\n​\n≤\n1\ndenote the utilization of the liquidity providers' capital prior to the transaction, i.e. the amount of the liquidity providers' capital that is in use prior to the current transaction\n0\n≤\nU\n^\nt\n≤\n1\n0 \\leq \\hat{U}_t \\leq 1\n0\n≤\nU\n^\nt\n​\n≤\n1\ndenote the utilization of the liquidity providers' capital after to the transaction, i.e. the amount of the liquidity providers' capital that would be in use if the user chose to execute their transaction\nU\nˉ\n\\bar{U}\nU\nˉ\ndenote the \"kink utilization\" where the slope on the interest rate changes\nR\n0\n,\nR\n1\n,\nR\n2\nR_0, R_1, R_2\nR\n0\n​\n,\nR\n1\n​\n,\nR\n2\n​\ndenote the parameters governing the interest rate model slopes\nR\n0\nR_0\nR\n0\n​\nis the interest rate that would be charged at 0% utilization\nR\n0\n+\nR\n1\nR_0 + R_1\nR\n0\n​\n+\nR\n1\n​\nis the interest rate that would be charged at \nU\nˉ\n%\n\\bar{U}\\% \nU\nˉ\n%\nutilization\nR\n0\n+\nR\n1\n+\nR\n2\nR_0 + R_1 + R_2\nR\n0\n​\n+\nR\n1\n​\n+\nR\n2\n​\nis the interest rate that would be charged at 100% utilization",
            "R\n0\nR_0\nR\n0\n​\nis the interest rate that would be charged at 0% utilization\nR\n0\n+\nR\n1\nR_0 + R_1\nR\n0\n​\n+\nR\n1\n​\nis the interest rate that would be charged at \nU\nˉ\n%\n\\bar{U}\\% \nU\nˉ\n%\nutilization\nR\n0\n+\nR\n1\n+\nR\n2\nR_0 + R_1 + R_2\nR\n0\n​\n+\nR\n1\n​\n+\nR\n2\n​\nis the interest rate that would be charged at 100% utilization"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/how-across-works/readme/validating-root-bundles": {
        "title": "Validating Root Bundles | Across Docs",
        "headers": [],
        "paragraphs": [
            "Root bundles instruct the Across system on how to transfer funds between smart contracts on different chains to refund relayers and fulfill user deposits.",
            "Last updated 1 year ago",
            "This explainer video explains why root bundles are critical to making the Across system work and how they are validated. Root bundles are optimistically validated and ultimately secured by the UMA Oracle. It is recommended that UMA voters and other actors in the UMA ecosystem have an understanding of how Across utilizes the UMA oracle."
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/how-across-works/readme/disputing-root-bundles": {
        "title": "Disputing Root Bundles | Across Docs",
        "headers": [
            "About",
            "Manual Dispute Procedure",
            "Automated Dispute Procedure"
        ],
        "paragraphs": [
            "Across requires proposals and disputes to be accompanied by a bond. This bond is returned if the proposal or dispute is correct, and is sacrificed if it is found to be incorrect. This protects against attempts to incorrectly move funds, as well as spam and other denial of service attempts.",
            "The Across Bond Token (ABT) is the bond collateral required by the HubPool contract. This is a WETH-like contract that is minted in return for depositing Ether, and can be redeemed for the underlying Ether at any time. ABT implements custom ERC20 transferFrom() logic in order to limit the addresses that are able to make HubPool root bundle proposals.",
            "Check the required bond token and amount (nominally 0.45 ABT) by calling bondToken() and bondAmount() on the HubPool.",
            "Mint the bond token as necessary by caling deposit() on the BondToken contract.",
            "Ensure that the HubPool has permission to pull the bond during the dispute. Increase the allowance as necessary by calling appprove() on the BondToken contract. The address to approve is 0xc186fa914353c44b2e33ebe05f21846f1048beda. ",
            "Call disputeRootBundle() on the HubPool.",
            "The Across relayer-v2 repository contains a utility script that automates each of the above steps. Prerequisites are:",
            "The relayer-v2 package must be installed.",
            "The mnemonic for an EOA must be set in the relayer-v2 .env file.",
            "The configured EOA must be funded with at least 0.45 ABT or ETH  (1 ABT == 1 ETH), plus additional ETH for gas to handle the necessary deposit, approval and/or dispute transactions.",
            "It is sufficient for the entire amount to be held in ETH, since the dispute script automates the steps of minting ABT and approving the HubPool to spend it.",
            "The actual amounts are subject to change based on the prevailing gas price at the time of the dispute, and the configured bond amount.",
            "Last updated 1 year ago"
        ],
        "lists": [
            "About\nManual Dispute Procedure\nAutomated Dispute Procedure"
        ],
        "tables": [],
        "code_blocks": [
            {
                "id": "8c699aa451b947a0b4d02c538aecff9d",
                "code": "$ git clone https://github.com/across-protocol/relayer-v2.git\n$ cd relayer-v2\n$ yarn install && yarn build\n\n# Copy the predefined sample config and update the MNEMONIC variable in\n# .env to match the relevant mnemonic.\n$ cp .env.example .env"
            },
            {
                "id": "61a5d2b170684ed5b96335bb2f2963e9",
                "code": "$ yarn dispute\n\n# The dispute script will dump information about the Bond Token and \n# latest HubPool proposal. If necessary, it will automatically mint the \n# requisite amount of the bond token and will approve the HubPool to use \n# it. At the conclusion, the script will provide the transaction hash of\n# the most recent proposal and will request to re-run with the flag\n#\n#     --txnHash <proposal-transaction-hash>\n# \n# Re-running the script with this additional argument will automatically \n# submit a dispute.\n\n$ yarn dispute --txnHash <proposal-transaction-hash>"
            }
        ]
    },
    "https://docs.across.to/developer-docs/developers/across-api": {
        "title": "Across API | Across Docs",
        "headers": [
            "Across API",
            "Source code:",
            "Caching & Liveness",
            "Calculating Suggested Fees",
            "Querying Limits",
            "Finding Available Routes"
        ],
        "paragraphs": [
            "The API is designed to be run serverlessly (without storing state) and is a wrapper on top of the SDK. Implementation here.",
            "Users of the Across API are requested to cache results for no longer than 300 seconds.",
            "The Across API serves data that is derived from the on-chain state of the Across contracts and relayer bots. The on-chain state is subject to change each block, and cached data can quickly become invalid as a result.",
            "The API uses the Across SDK under the hood, but offers a convenient way to get suggested fees when placing a Deposit transaction.",
            "Example:",
            "You can visit this example in your browser: Link.",
            "Or curl it on the CLI:",
            "curl \"https://across.to/api/suggested-fees?token=0x7f5c764cbc14f9669b88837ca1490cca17c31607&destinationChainId=42161&amount=100000000000\"",
            "Note: When filling relays, it is strongly recommended to use the Across SDK relayFeeCalculator. Using the suggested-fees API endpoint is done at the relayer's own risk.",
            "All API calls use https://across.to/apias the host.",
            "Path: /suggested-fees",
            "Method: GET",
            "Query Params",
            "token",
            "Address of token contract to transfer. For ETH (or other native tokens, like matic) use, use the wrapped address, like WETH.\n\nNote: the address provided can be the token address on any chain. In the unlikely event where two different tokens have the same address on different chains, you can use the optional chainId parameter defined below to indicate which chain should be used.",
            "0x7f5c764cbc14f9669b88837ca1490cca17c31607",
            "destinationChainId",
            "The intended destination of the transfer.",
            "42161",
            "amount",
            "Amount of the token to transfer. Note: this amount is in the native decimals of the token. So, for WETH, this would be the amount of human-readable WETH multiplied by 1e18. For USDC, you would multiply the number of human-readable USDC by 1e6.",
            "100000000000",
            "originChainId (optional)",
            "Used to specify which chain where the specified token address exists. Note: this is only needed to disambiguate when there are matching addresses on different chains. Otherwise, this can be inferred by the API.",
            "10",
            "recipient (optional)",
            "The recipient of the deposit. This can be an EOA or a contract. If this is an EOA and message is defined, then the API will throw a 4xx error.",
            "0xc186fa914353c44b2e33ebe05f21846f1048beda",
            "message (optional)",
            "Specifies calldata that is passed to the recipient if recipient is a contract address. This calldata is passed to the recipient via the recipient's handleAcrossMessage() public function here. The length of this value is constrained by the API to ~4096 chars minus the length of the full URL.",
            "0xABC123",
            "relayer (optional)",
            "Optionally override the relayer address used to simulate the fillRelay() call that estimates the gas costs needed to fill a deposit. This simulation result impacts the returned suggested-fees. The reason to customize the EOA would be primarily if the recipientAddress is a contract and requires a certain relayer to submit the fill, or if one specific relayer has the necessary token balance to make the fill.",
            "0x428ab2ba90eba0a4be7af34c9ac451ab061ac010",
            "timestamp (optional)",
            "The quote timestamp used to compute the LP fees. When bridging with across, the user only specifies the quote timestamp in their transaction. The relayer then determines the utilization at that timestamp to determine the user's fee. This timestamp must be close (within 10 minutes or so) to the current time on the chain where the user is depositing funds and it should be <= the current block timestamp on mainnet. This allows the user to know exactly what LP fee they will pay before sending the transaction.\n\nIf this value isn't provided in the request, the API will assume the latest block timestamp on mainnet.",
            "1653547649",
            "Returns a JSON object with the following properties:",
            "relayFeePct",
            "The percentage of the transfer amount that should go to the relayer as a fee. This is the strongly recommended minimum value to ensure a relayer will perform the transfer under the current network conditions.",
            "",
            "The value returned in this field is guaranteed to be at least 0.03% in order to meet minimum relayer fee requirements.",
            "",
            "Note: 1% is represented as 1e16, 100% is 1e18, 50% is 5e17, etc. These values are in the same format that the contract understands.",
            "61762946000000000",
            "lpFeePct",
            "The percent of the amount that will go to the LPs as a fee for borrowing their funds.\n\nThe formatting of the percentage is the same as relayFeePct .",
            "1252191895805000",
            "timestamp",
            "The quote timestamp that was used to compute the lpFeePct.",
            "",
            "To pay the quoted LP fee,  the user would need to pass this quote timestamp to the protocol when sending their bridge transaction.",
            "1646925270",
            "Errors: ",
            "400: invalid input.",
            "500: an unexpected error within the API.",
            "The API uses the UMA SDK under the hood, but offers a convenient way to get transfer limits.",
            "Example: Finding limits for bridging USDC from Optimism to Arbitrum.",
            "You can visit this example in your browser: Link",
            "Or curl it on the CLI: ",
            "curl \"https://across.to/api/limits?token=0x7f5c764cbc14f9669b88837ca1490cca17c31607&destinationChainId=42161\"",
            "All API calls use https://across.to/apias the host.",
            "Path: /limits",
            "Method: GET",
            "Query Params",
            "token",
            "Address of token contract to transfer. For ETH (or other native tokens, like matic) use, use the wrapped address, like WETH.\n\nNote: the address provided can be the token address on any chain. In the unlikely event where two different tokens have the same address on different chains, you can use the optional chainId parameter defined below to indicate which chain should be used.",
            "0x7f5c764cbc14f9669b88837ca1490cca17c31607",
            "destinationChainId",
            "The intended destination of the transfer.",
            "42161",
            "originChainId (optional)",
            "Used to specify which chain where the specified token address exists. Note: this is only needed to disambiguate when there are matching addresses on different chains. In that case, an arbitrary one will be chosen, so it is recommended that this is always provided.",
            "10",
            "Returns a JSON object with the following properties:",
            "minDeposit",
            "The minimum deposit size in the tokens' units.",
            "",
            "Note: USDC has 6 decimals, so this value would be the number of USDC multiplied by 1e6. For WETH, that would be 1e18.",
            "7799819",
            "maxDeposit",
            "The maximum deposit size in the tokens' units.",
            "",
            "Note: The formatting of this number is the same as minDeposit.",
            "22287428516241",
            "maxDepositInstant",
            "The max deposit size that can be relayed \"instantly\" on the destination chain. Instantly means that there is relayer capital readily available and that a relayer is expected to relay within 1-4 minutes of the deposit.",
            "201958902363",
            "maxDepositShortDelay",
            "The max deposit size that can be relayed with a \"short delay\" on the destination chain. This means that there is relayer capital available on mainnet and that a relayer will immediately begin moving that capital over the canonical bridge to relay the deposit. Depending on the chain, the time for this can vary. Polygon is the worst case where it can take between 20 and 35 minutes for the relayer to receive the funds and relay. Arbitrum is much faster, with a range between 5 and 15 minutes.\n\nNote: if the transfer size is greater than this, the estimate should be between 2-4 hours for a slow relay to be processed from the mainnet pool.",
            "2045367713809",
            "Errors: ",
            "400: invalid input.",
            "500: an unexpected error within the API.",
            "Example:",
            "You can visit this example in your browser: Link",
            "Or curl it on the CLI:",
            "curl \"https://across.to/api/available-routes\"",
            "All API calls use https://across.to/apias the host.",
            "Path: /available-routes",
            "Method: GET",
            "Query Params",
            "originChainId",
            "The chain ID of the originating chain to a bridge transfer. ",
            "",
            "Note: This is an optional query parameter. This parameter will filter the response JSON based. This filter can be used in addition to additional parameters to create a custom filter.",
            "1",
            "destinationChainId",
            "The chain ID of the destination chain to a bridge transfer. ",
            "",
            "Note: This is an optional query parameter. This parameter will filter the response JSON based. This filter can be used in addition to additional parameters to create a custom filter.",
            "10",
            "originToken",
            "The token address of the originating bridge transfer. ",
            "Must be a valid ERC-20 token address. ",
            "",
            "Note: This is an optional query parameter. This parameter will filter the response JSON based. This filter can be used in addition to additional parameters to create a custom filter.",
            "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",
            "destinationToken",
            "The token address that funds will be transferred to at the destination chain. Must be a valid ERC-20 token address. ",
            "",
            "Note: This is an optional query parameter. This parameter will filter the response JSON based. This filter can be used in addition to additional parameters to create a custom filter.",
            "0x4200000000000000000000000000000000000006",
            "Returns a JSON array of Objects with the following properties:",
            "originChainId",
            "The chain ID of the originating chain to a bridge transfer. ",
            "1",
            "destinationChainId",
            "The chain ID of the destination chain to a bridge transfer. ",
            "10",
            "originToken",
            "The token address of the originating bridge transfer. ",
            "\nNote: this will be a valid ERC-20 token address. ",
            "0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2",
            "destinationToken",
            "The token address that funds will be transferred to at the destination chain.\n\nNote: this will be a valid ERC-20 token address. ",
            "0x4200000000000000000000000000000000000006",
            "Errors: ",
            "400: invalid input.",
            "500: an unexpected error within the API.",
            "Last updated 1 year ago"
        ],
        "lists": [
            "Source code:\nCaching & Liveness\nCalculating Suggested Fees\nQuerying Limits\nFinding Available Routes",
            "400: invalid input.\n500: an unexpected error within the API.",
            "400: invalid input.\n500: an unexpected error within the API.",
            "400: invalid input.\n500: an unexpected error within the API."
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/across-sdk": {
        "title": "Across SDK | Across Docs",
        "headers": [
            "Across SDK",
            "About the SDK",
            "How can I use the SDK?",
            "If I want to integrate Across into my dApp, should I use the SDK or the API?",
            "Installation",
            "Basic Usage"
        ],
        "paragraphs": [
            "The Across SDK is written and maintained by the engineering team at Risk Labs.",
            "It is written in typescript and available on NPM at @across-protocol/sdk-v2. It's compatible with both Node JS environments and in the browser.",
            "The SDK can be used currently to query suggested deposit fees and limits, and get liquidity pool statistics. It is imported and used in the API's implementation.",
            "We recommend using the API, which wraps SDK functions and has an easier interface. However, if speed is a concern then we recommend reviewing the API implementation of the SDK to understand best how to use the SDK. ",
            "To add the SDK to your project, use npm or yarn to npm install @across-protocol/sdk-v2 or yarn add @across-protocol/sdk-v2.",
            "This can be used either in a frontend application or a node js project. ",
            "You can read about the different SDK modules on the Github README page. For convenience, the available modules are:",
            "lpFeeCalculator: Get liquidity provider fee that will be charged on deposit for its quoteTimestamp",
            "relayFeeCalculator: Get suggested relayerFeePct for a deposit, which accounts for opportunity cost of capital and gas costs. If the depositor opts to set this fee lower than the suggested fee, then there is a chance that the deposit goes unfilled for a long time.",
            "pool: Get HubPool statistics, such as available liquidReserves that be used to refund relayers and estimatedApy for liquidity providers.",
            "Last updated 2 years ago"
        ],
        "lists": [
            "About the SDK\nHow can I use the SDK?\nIf I want to integrate Across into my dApp, should I use the SDK or the API?\nInstallation\nBasic Usage",
            "lpFeeCalculator: Get \nliquidity provider fee\n that will be charged on deposit for its \nquoteTimestamp\nrelayFeeCalculator: Get suggested \nrelayerFeePct\n for a deposit, which accounts for \nopportunity cost of capital and gas costs\n. If the depositor opts to set this fee lower than the suggested fee, then there is a chance that the deposit goes unfilled for a long time.\npool: Get HubPool statistics, such as available \nliquidReserves\n that be used to refund relayers and \nestimatedApy\n for \nliquidity providers\n."
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses": {
        "title": "Contract Addresses | Across Docs",
        "headers": [
            "Contract Addresses"
        ],
        "paragraphs": [
            "You can find the contract addresses on the following pages:",
            "Mainnet",
            "Arbitrum",
            "Optimism",
            "Base",
            "zkSync",
            "Polygon",
            "Boba",
            "These addresses can also be found on the Across github",
            "Last updated 1 year ago"
        ],
        "lists": [
            "Mainnet\nArbitrum\nOptimism\nBase\nzkSync\nPolygon\nBoba"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/mainnet-chain-id-1": {
        "title": "Mainnet (Chain ID: 1) | Across Docs",
        "headers": [
            "Mainnet (Chain ID: 1)"
        ],
        "paragraphs": [
            "",
            "LPTokenFactory",
            "0x7dB69eb9F52eD773E9b03f5068A1ea0275b2fD9d",
            "HubPool",
            "0xc186fA914353c44b2E33eBE05f21846F1048bEda",
            "Optimism_Adapter",
            "0xAd1b0a86c98703fd5F4E56fff04F6b2D9b9f246F",
            "Boba_Adapter",
            "0x33B0Ec794c15D6Cc705818E70d4CaCe7bCfB5Af3",
            "Arbitrum_Adapter",
            "0x29528780E29abb8Af95a5e5a125b94766987543F",
            "Ethereum_Adapter",
            "0x527E872a5c3f0C7c24Fe33F2593cFB890a285084",
            "Ethereum_SpokePool",
            "0x5c7BCd6E7De5423a257D81B442095A1a6ced35C5",
            "PolygonTokenBridger",
            "0x0330E9b4D0325cCfF515E81DFbc7754F2a02ac57",
            "Polygon_Adapter",
            "0x3E94e8d4316a1eBfb2245E45E6F0B8724094CE1A",
            "zkSync Adapter",
            "0xE233009838CB898b50e0012a6E783FC9FeE447FB",
            "Base Adapter",
            "0x2d8B1e2B0Dff62DF132d23BEa68a6D2c4D20046E",
            "AcrossConfigStore",
            "0x3B03509645713718B78951126E0A6de6f10043f5",
            "AcceleratingDistributor",
            "0x9040e41eF5E8b281535a96D9a48aCb8cfaBD9a48",
            "AcrossMerkleDistributor",
            "0xE50b2cEAC4f60E840Ae513924033E753e2366487",
            "ClaimAndStake",
            "0x985e8A89Dd6Af8896Ef075c8dd93512433dc5829",
            "Across Governance Token",
            "0x44108f0223A3C3028F5Fe7AEC7f9bb2E66beF82F",
            "Across Bond Token",
            "0xee1DC6BCF1Ee967a350e9aC6CaaAA236109002ea",
            "",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/arbitrum-chain-id-42161": {
        "title": "Arbitrum (Chain ID: 42161) | Across Docs",
        "headers": [],
        "paragraphs": [
            "",
            "Arbitrum_SpokePool",
            "0xe35e9842fceaca96570b734083f4a58e8f7c5f2a",
            "Across Governance Token",
            "0x53691596d1BCe8CEa565b84d4915e69e03d9C99d",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/optimism-chain-id-10": {
        "title": "Optimism (Chain ID: 10) | Across Docs",
        "headers": [],
        "paragraphs": [
            "",
            "Optimism_SpokePool",
            "0x6f26Bf09B1C792e3228e5467807a900A503c0281",
            "Across Governance Token",
            "0xFf733b2A3557a7ed6697007ab5D11B79FdD1b76B",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/base-chain-id-8453": {
        "title": "Base (Chain ID: 8453) | Across Docs",
        "headers": [],
        "paragraphs": [
            "",
            "Base_SpokePool",
            "0x09aea4b2242abC8bb4BB78D537A67a245A7bEC64",
            "",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/zksync-chain-id-324": {
        "title": "zkSync (Chain ID: 324) | Across Docs",
        "headers": [],
        "paragraphs": [
            "",
            "zkSync_SpokePool",
            "0xE0B015E54d54fc84a6cB9B666099c46adE9335FF",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/contract-addresses/polygon-chain-id-137": {
        "title": "Polygon (Chain ID: 137) | Across Docs",
        "headers": [],
        "paragraphs": [
            "",
            "PolygonTokenBridger",
            "0x0330E9b4D0325cCfF515E81DFbc7754F2a02ac57",
            "Polygon_SpokePool",
            "0x9295ee1d8C5b022Be115A2AD3c30C72E34e7F096",
            "Across Governance Token",
            "0xF328b73B6c685831F238c30a23Fc19140CB4D8FC",
            "Last updated 1 year ago"
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/selected-contract-functions": {
        "title": "Selected Contract Functions | Across Docs",
        "headers": [
            "SpokePool state-modifying functions",
            "deposit ",
            "speedUpDeposit "
        ],
        "paragraphs": [
            "Explanation of most commonly used smart contract functions",
            "The spoke pool contract is where deposits are originated and fulfilled. ",
            "This triggers a deposit request of tokens to another chain with the following parameters. The originChainId is automatically set to the chain ID on which the SpokePool is deployed. For example, sending a deposit from the Optimism_SpokePool will set its originChainId equal to 10. ",
            "Note on sending ETH: deposit is a payable function meaning it is possible to send native ETH instead of wrapped ETH (i.e. WETH). If you choose to send ETH, you must set msg.value equal to amount.",
            "Note on approvals: the caller must approve the SpokePool to transfer amount of tokens.",
            "Note on amount limits: If the amount is set too high, it can take a while for the deposit to be filled depending on available relayer liquidity. If the amount is set too low, it can be unprofitable to relay regardless of the relayer fee %. Query the suggested max and min limits here. The contracts will not revert if the amount is set outside of the recommended range, so it is highly recommended to set amount within the suggested limits to avoid locking up funds for an unexpected length of time.",
            "Note on setting quoteTimestamp: ",
            "Call the read-only function getCurrentTime() to get the current UNIX timestamp on the origin chain. e.g. this could return: 1665418548.",
            "Call the read-only function depositQuoteTimeBuffer() to get the buffer around the current time that the quoteTimestamp must be set to. e.g. this could return: 600.",
            "quoteTimestamp must be <= currentTime + buffer and >= currentTime - buffer.",
            "address",
            "recipient",
            "Receiver of bridged funds on destination chain.",
            "address",
            "originToken",
            "Bridged token address on origin chain.",
            "uint256",
            "amount",
            "Amount of tokens to send on origin chain. Receiver receives this amount minus fees on destination chain.",
            "uint256",
            "destinationChainId",
            "Where bridged funds should be sent to recipient. Recipient will receive the equivalent of the originToken on the destination chain. The mapping of  destination and origin tokens can be queried  here.",
            "uint64",
            "relayerFeePct",
            "% of amount to pay to relayer. Must be less than 0.5e18 (i.e. 50%). Suggested fees can be queried here. Be careful: if this % is set too low, relayers could be disincentivized to fill this deposit quickly. This can be sped up by calling speedUpDeposit. ",
            "uint32",
            "quoteTimestamp",
            "Timestamp of deposit. Used by relayers to compute the LP fee % for the deposit. Must be withindepositQuoteTimeBuffer() of the current time.",
            "bytes",
            "message",
            "Data that can be passed to the recipient if it is a contract. If no message is to be sent, set this field to an empty bytes array: \"\"(i.e. bytes` of length 0, or the \"empty string\").\n\nSee Composable Bridging for examples on how messaging can be used.",
            "uint256",
            "maxCount",
            "This parameter can be set to protect against front-running in the new UBA fee model. Stay tuned for updates about this feature. For now, set this to UINT256.MAX_UINT to avoid deposit reverts.",
            "Some of a pending deposit's parameters can be modified by calling this function. If a deposit has been completed already, this function will not revert but it won't be able to be filled anymore with the updated params. It is the responsibility of the depositor to verify that the deposit has not been fully filled before calling this function.",
            "A depositor can request modifications by signing a hash containing the updated details and information uniquely identifying the deposit to relay. This information ensures that this signature cannot be re-used for other deposits.",
            "We use the EIP-712 standard for hashing and signing typed data. Specifically, we use the version of the encoding known as \"v4\", as implemented by the JSON RPC method eth_signedTypedDataV4 in MetaMask. ",
            "You can see how the message to be signed is reconstructed in Solidity here.",
            "Successfully calling this function will emit an event RequestedSpeedUpDeposit which can be used by relayers to fill the original deposit with the new parameters.  Depositors should assume that the parameters emitted with the highest relayerFeePct will be used, since they are incentivized to use the highest fee possible.",
            "Any relayer can use updated deposit parameters by calling fillRelayWithUpdatedDeposit instead of fillRelay.",
            "address",
            "depositor",
            "Sender of deposit to be sped up. Does not need to equal msg.sender",
            "int64",
            "updatedRelayerFeePct",
            "New relayer fee % that relayers can use when calling fillDepositWithUpdatedDeposit",
            "uint32",
            "depositId",
            "UUID of deposit to be sped up",
            "address",
            "updatedRecipient",
            "New recipient of deposit.",
            "bytes",
            "updatedMessage",
            "Updated data that is sent to updatedRecipient. As described in section above, this should be set to 0x for the forseeable future.",
            "bytes",
            "depositorSignature",
            "Signed message containing contents here",
            "Last updated 1 year ago"
        ],
        "lists": [
            "SpokePool state-modifying functions\ndeposit \nspeedUpDeposit"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/running-a-relayer": {
        "title": "Running a Relayer | Across Docs",
        "headers": [
            "Requirements",
            "Installation",
            "Updating",
            "Configuration",
            "Notes on requirements to RPC Providers",
            "Using a Redis in-memory database to improve performance",
            "Managing cross chain inventory",
            "Security Considerations",
            "Running the Relayer for the first time",
            "Which account will be used to send transactions?",
            "Which tokens can be relayed?",
            "How can I learn more about the code behind the bot's logic?",
            "Auxiliary Topics:",
            "Across V2 smart contracts",
            "Across V2 UMIP",
            "Additional relayer FAQs:",
            "What is a root bundle?",
            "How often do new root bundles get published and executed?"
        ],
        "paragraphs": [
            "Technical instructions that someone comfortable with command line can easily follow to run their own Across V2 relayer",
            "",
            "All of the code in this repository can be found in this GitHub repository.",
            "The Across v2 Relay Bot is implemented in Node.js and is capable of running on a variety of platforms. See the following table for platform recommendations.",
            "CPU",
            "64-bit Dual Core @ 2+ GHz",
            "RAM",
            "4GB",
            "OS",
            "UNIX-like (GNU/Linux, MacOS)",
            "A helper script is available to automate updates. This performs the following actions:",
            "Flushes any existing installed dependencies.",
            "Pulls down the latest relayer-v2 commit.",
            "Installs all dependencies and builds the relayer.",
            "Displays the latest commit in the relayer-v2 repository.",
            "This update helper is offered as a convenience. After update, the operator must manually verify that the update succeeded and that the commit shown matches the intended target.",
            "This section describes the environment variable configuration that the bot requires in order to operate. This is the minimum configuration for running a relayer that operates on all supported tokens for all destination chains. You just need to change the configs at the top.",
            "Operators can exclude tokens/destination chains by not having a balance for that token on that destination chain. For customizing tokens/destination chains while having balances, see the advanced section for all supported configs.",
            "The relayer is dependent on querying historical blocks on each chain. The RPC provider must therefore support making archive queries. If the RPC provider cannot service archive queries then the relayer will fail with reports of obscure RPC errors.",
            "The relayer queries a lot of events from each chain's RPC that Across supports. Therefore, we use an in-memory database to improve performance and cache repeated RPC requests. Installation instructions can be found here. Once installed, run redis-server in one terminal window and then open another one to continue running the relayer from.",
            "The redis server is used to cache the responses of RPC-intensive repetitive requests, like eth_getLogs, or internally-computed data like getBlockForTimestamp. Caching of data is subject to the age of the input response from the RPC provider, such that a minimum block age is required before it will be retained. This provides some protection against caching invalid data, or valid data becoming invalid (or otherwise changing) due to chain forks/re-orgs.",
            "The relayer bot is designed to use the same account across each of the supported chains: Ethereum, Optimism, Polygon, Boba and Arbitrum. Therefore, the bot can be told to automatically rebalance its inventory across chains and target some allocation.",
            "The best way to demonstrate how rebalancing can be customized is to walk through an example setting of the RELAYER_INVENTORY_CONFIG environment variable:",
            "First let's look at the \"tokenConfig\". This informs the relayer how it should distribute its token balances across the different networks. Each of the keys of the \"tokenConfig\" object (\"0xC02\", \"0x6B1\", \"0xA0b\", \"0x226\") represent the Mainnet address of the ERC20 token that we want to automatically control inventory for. So, in order, the tokens in the example config are WETH, DAI, USDC, and WBTC. ",
            "Diving into WETH's token configuration, notice that it has an object containing \"targetPct\", \"thresholdPct\", \"unwrapWethThreshold\", and \"unwrapWethTarget\" mapped to each network ID. The \"targetPct\" and \"thresholdPct\" instructs the relayer account on Mainnet when to send funds to the network with the associated network ID. ",
            "The relayer is always aware of its aggregate funds across all chains, so for example if the account has 10 WETH on Mainnet, 5 on Optimism, 4 on Arbitrum, 3 on Polygon, and 2 on BOBA, then it has a total of 24 WETH. The allocations are: 5/24 on Optimism, 4/24 on Arbitrum, etc.",
            "When the relayer's allocation for a specific chain drops below the \"thresholdPct\", then the relayer will send funds from its Mainnet account to the chain with the shortfall so that its post-transfer allocation is increased to the \"targetPct\". In the example config above, if the allocation percent on Optimism were to drop below 5%, then the relayer would send funds from Mainnet to Optimism to bring its allocation to 8%.",
            "All funds are sent through the canonical L1-->L2 bridges and the logic implementing such rebalances can be found here.",
            "Note that the \"targetPct\" and \"thresholdPct\" are unused for the mainnet token config (i.e. for the row with ID \"1\") but are included to avoid a compile-time error.",
            "By default, all fills sent by the relayer are set to be repaid on Mainnet, so if the relayer sent a fill on Polygon for USDC, then it will receive the relayed USDC amount plus a relayer fee on Mainnet. This means that over time, the relayer's allocation percent on Polygon will decrease.",
            "Therefore, the inventory rebalance logic also provides a function that overrides the repayment chain ID to try to maintain its target allocation. This happens automatically before submitting any fill by this function.",
            "The \"unwrapWethThreshold\" and \"unwrapWethTarget\" tell the relayer when to unwrap WETH into ETH to keep enough ETH on hand for paying gas costs. These configs are unused on Polygon which does not pay gas in ETH. Moreover, these configs should only be set in the token configuration for WETH (i.e. \"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\").",
            "If the relayer's ETH balance drops below the \"unwrapWethThreshold\", then it will unwrap enough WETH to increase its ETH balance to the \"unwrapWethTarget\" value.",
            "This logic can be found here.",
            "Wrap ETH",
            "The \"wrapEtherThreshold\" is used only for Optimism and Boba, the two OVM networks which requires that ETH, not WETH, is sent over the bridge from L2 to L1. Because of this fact, the relayer can end up holding a lot of ETH on L2 and not enough WETH. ",
            "If the relayer account's ETH balance on Optimism or Boba drops below this value, then it will wrap any excess ETH above the value into WETH. Its important that this value is set higher than the \"unwrapWethTarget\" for WETH for Optimism and Boba. In the example above, the \"unwrapWethTarget/Threshold\" is 1.5/0.75 and the \"wrapEtherThreshold\" is 2, meaning that the relayer on Optimism and Boba will unwrap WETH if its ETH balance is less than 0.75 and increase its balance to 1.5, and will wrap ETH if its balance is above 2.",
            "Logic for wrapping ETH can be found here.",
            "This description describes a basic set of security considerations that relay bot operators should be aware of. See Recommendations for suggestions on how to improve the security of relay bot instances.",
            "This is not a complete security guide. Relay bot operators solely assume the risk of loss of fu",
            "The Across v2 relay bot communicates with various public RPC endpoints, and thus requires outbound network access. Unknown/untrusted network actors may be able to communicate with the relay bot host. It's important to reduce the attack surface area that the host environment exposes, in terms of:",
            "Network services listening on public interfaces.",
            "Interfaces opened for remote administration, and their permitted authentication mechanisms.",
            "Third-party installations that may autonomously communicate (i.e. phone home) over the network.",
            "The Across relay bot requires an in-memory copy of an Ethereum private key in order to sign relay transactions. This in-memory copy is typically loaded from the execution environment, via the following environment variables:",
            "MNEMONIC (when run with --wallet mnemonic)",
            "PRIVATE_KEY (when run with --wallet privateKey)",
            "When not specified directly via environment variables, these configuration items can be saved in the filesystem in a .env file, in the relayer-v2 working directory. Relay bot operators should be aware of at least the following:",
            "Depending on the .env mode flags, users or programs with filesystem access may be able to read secrets from the .env file.",
            "When storing secrets on disk, anyone with raw disk access may be able to override filesystem permissions and recover file contents. This includes:",
            "People with system administrative privileges.",
            "People with physical disk/hardware access.",
            "Vendors of cloud-based execution environments (i.e. VM hosts).",
            "During operation, the relayer-v2 bot retains secret keying information in-memory. Anyone with the ability to dump application or system memory may be able to retrieve secret keying material.",
            "The Across relay bot supports a bespoke Google Cloud key management interface (gckms), whereby the bot retrieves keying material from a secured, trusted key management. Keying material retrieved over the gckms interface is stored locally in-memory, but is not saved to disk.",
            "The gckms interface is tailored for use by Risk Labs and is not currently intended for use by third-party bot operators. Support for generic third-party key management systems may be added to the relay bot in future.",
            "Deploy relay bot instances in isolated environments (i.e. dedicated VM/container environment, or dedicated hardware).",
            "Adhere to basic system administration and hardening practices. NIST 800-123 Guide to General Server Security may be useful.",
            "Never install software from untrusted sources, and verify software packages before installation/execution.",
            "Limit the ability for malicious network actors to gain system access by restricting inbound network traffic to trusted hosts and/or services. Drop all other traffic.",
            "Avoid the use of password-based authentication schemes for remote login services. Use key-based authentication (i.e. SSH keys) instead.",
            "Ensure that filesystem ownership and permission flags are set appropriately at all times. These attributes should be periodically reviewed for correctness.",
            "Ensure that parties with raw disk access are trusted.",
            "Note: Where untrusted or unknown parties may have raw disk access, filesystem encryption schemes may be useful in reducing the opportunity for theft of secret keying material.",
            "Ensure that parties with the ability to dump system and/or application memory are trusted.",
            "Note: This applies primarily to vendors providing virtualised execution environments - i.e. cloud/VM hosts.",
            "Maintain at least one secure offline copy (backup) of the secret keying material. Backups should be periodically reviewed for correctness.",
            "Once you've installed and built the relayer code and set your desired environment variables, you're all set to run the relayer code. The entry point to run the code is the command (choose one of the following):",
            "This will run the relayer in \"simulation mode\" meaning that it will simulate the transactions that would fill deposits, but will not submit them. This will give you a chance to review transactions before funds are sent. ",
            "On the first run, the bot should approve various SpokePool contracts to withdraw ERC20's from it. This is required to fulfill relays. These approval transactions are not \"simulated\" currently and will still be sent even when running in simulation mode. Approvals will only be sent for tokens with nonzero balances in the relayer account.",
            "If the bot successfully completes a run, you will see this log before it exits: ",
            "When you feel ready to run the relayer and send your first relay, set SEND_RELAYS=true to exit simulation mode!",
            "The first account associated with the MNEMONIC set in the environment will be used. Be sure to add ETH and any token balances to its account so that it can send relays.",
            "WETH, USDC, DAI, WBTC, UMA. This list is likely to require updates in the future. Work is being done to automate the latest token list.",
            "The relayer's entry point file is Relayer/index.ts.",
            "The relayer bot first identifies all unfilled deposits across each of the chains. Deposit events are fetched here by the SpokePoolClient for each chain. Using these unfilled deposits as input, the relayer will attempt to fill them based if it has the token balance on the destination chain to do so.",
            "The smart contracts can be found at this repository. They have been audited by OpenZeppelin. A high level video overview of the contract architecture can be found here.",
            "UMIP-157 explains how \"valid\" relays are identified, which are relays that correctly filled a deposit and paid the correct fees and are due to be returned their relayed amount plus a relay fee.",
            "The relayer bot code is supposed to be one implementation of UMIP-157.",
            "A root bundle for a block range is a set of three Merkle roots that contains all of the information necessary to refund relayers who fulfilled a deposit during the block range. A root bundle is valid only if it contains all of the expected information for a block range. This UMIP explains at length exactly how to construct a valid root bundle.",
            "The current liveness period is 7200 seconds or 2 hours. You can always query it on the HubPool by calling the read-only method liveness(), and only one root bundle can be proposed at a time. So, the fastest cadence for root bundles being proposed is every 2 hours. Each root bundle contains approximately all of the relayer refunds up to the current time (as of the proposal) and as old as right after the preceding root bundle proposal time. A 'dataworker' is what we refer to as the agent who gathers all Fill and Deposit events from all of the chains that Across V2 supports bridging to and from in order to construct these Merkle root bundles. A dataworker could choose to propose a new root bundle right after the current one passes liveness, or it can choose to wait. Realistically, we expect that a dataworker will only submit a new root bundle after it contains a certain volume of refunds, for capital efficiency reasons. So to summarize:",
            "Relayer refunds are contained in root bundles that are optimistically published to the HubPool",
            "Once the root bundle proposal passes liveness, refunds can be sent to relayers. At this point, relayers are made whole and receive an additional relayer fee",
            "The fastest cadence of root bundle proposals is once every two hours. In the worst case, root bundles can take much longer if volume is low across the system",
            "A dataworker can propose a bundle at any time. However, if a current bundle is in liveness - it is required that either that bundle be disputed or the bundle passes liveness and is executed before a new bundle is proposed.",
            "",
            "",
            "Last updated 11 months ago"
        ],
        "lists": [
            "Flushes any existing installed dependencies.\nPulls down the latest relayer-v2 commit.\nInstalls all dependencies and builds the relayer.\nDisplays the latest commit in the relayer-v2 repository.",
            "Network services listening on public interfaces.\nInterfaces opened for remote administration, and their permitted authentication mechanisms.\nThird-party installations that may autonomously communicate (i.e. phone home) over the network.",
            "MNEMONIC (when run with --wallet mnemonic)\nPRIVATE_KEY (when run with --wallet privateKey)",
            "Relayer refunds are contained in root bundles that are optimistically published to the HubPool\nOnce the root bundle proposal passes liveness, refunds can be sent to relayers. At this point, relayers are made whole and receive an additional relayer fee\nThe fastest cadence of root bundle proposals is once every two hours. In the worst case, root bundles can take much longer if volume is low across the system\nA dataworker can propose a bundle at any time. However, if a current bundle is in liveness - it is required that either that bundle be disputed or the bundle passes liveness and is executed before a new bundle is proposed."
        ],
        "tables": [],
        "code_blocks": [
            {
                "id": "6d6e5e39786745f7b116710fc81f9f09",
                "code": "# Clone relayer code with Github CLI or git clone.\ngit clone https://github.com/across-protocol/relayer-v2.git\ncd relayer-v2\n\n# Establish environment file and restrict filesystem permissions.\ntouch .env\nchmod 0600 .env\n\n# The private key or seed phrase for the relayer can be stored in a\n# dedicated file. Operators should be especially careful to set the file\n# permissions correctly and to backup any secrets securely. The path to\n# the secret is set via the SECRET env var (optionally specified in\n# .env). The file may be stored anywhere in the file system but must be\n# readable by the user that runs the relayer.\ntouch .secret\nchown <user>:<group> .secret\nchmod 0600 .secret\necho <private-key-or-mnemonic> > .secret\nchmod 0400 .secret\n\n# Install dependencies and build relayer.\n# Nodejs and yarn are required.\nyarn install\nyarn build\n\n# Run unit tests.\nyarn test\n\n# Apply any necessary changes to .env and mark it read-only.\nchmod 0400 .env"
            },
            {
                "id": "71dfd61e1bfb47e4b70f8ed580a9506f",
                "code": "yarn update"
            },
            {
                "id": "ffd34a5f1b3c4e75b17df4202686db1b",
                "code": "# Do change the following configs:\n\n# Amount of time to wait (in seconds) between bot loops. This can be\n# set to 0 to run once and exit (recommended). Operators can schedule\n# relayer externally (i.e. via cron or another job scheduler).\n#\n# If set to a non-zero value such as 10, the bot will run through all\n# instructions, sleep for 10 seconds, then run again. This mode is not\n# recommended.\nPOLLING_DELAY=0\n\n# SECRET identifies a separate file containing a private key or mnemonic\n# to be used by the relayer. The file must contain only the raw key or\n# mnemonic. Critical: Ensure that the filesystem permissions for this\n# file are properly configured (i.e. owned by one specific user, not\n# world-readable, ...).\n# SECRET=<path-to-private-key-or-mnemonic>\nSECRET=.secret\n\n# Define RPC providers for each chain. One RPC provider is specified\n# per line. Format:\n# RPC_PROVIDER_<PROVIDER-NAME>_<CHAIN-ID>=<ENDPOINT-URL>\nRPC_PROVIDER_INFURA_1=https://mainnet.infura.io/v3/...\nRPC_PROVIDER_INFURA_10=https://optimism-mainnet.infura.io/v3/...\n# Repeat this for each supported chain (1, 10, 137, 42161, ...)\n\nRPC_PROVIDER_ALCHEMY_1=https://eth-mainnet.g.alchemy.com/v2/...\n# Repeat this for each supported chain (1, 10, 137, 42161, ...)\n\n# Specify RPC provider preferences. The first provider is always used.\n# Subsequent providers are used as backups in event of a higher\n# priority provider being unavailable, or failing quorum. If\n# NODE_QUORUM is > 1, there must be at least NODE_QUROUM number of\n# providers defined, and some RPC queries will be performed against\n# NODE_QUORUM number of providers in parallel.\nRPC_PROVIDERS=INFURA,ALCHEMY\n\n# Per-chain overrides are possible. In the example below, LlamaNodes\n# is preferred on Ethereum and Polygon.\nRPC_PROVIDERS_1=LLAMANODES,INFURA,ALCHEMY\nRPC_PROVIDERS_137=LLAMANODES,INFURA,ALCHEMY\n\n# Enable on-chain relayer functionality. This is disabled by default\n# and must be explicitly enabled for the relayer to send transactions.\n# This can be used to run bot in \"simulation mode\". To turn bot on,\n# set to \"true\".\nSEND_RELAYS=false\n\n# Deposit lookback window, specified in seconds. This is subtracted\n# from the current time and is resolved to a block number on each\n# chain, effectively controlling how far back in time the relayer\n# will scan for unfilled deposits. \nMAX_RELAYER_DEPOSIT_LOOK_BACK=1800\n\n# Gas fees are difficult to estimate correctly, and the strategy for\n# setting  gas might depend on the priorities of the relay bot operator.\n# Gas fees can therefore be scaled on each chain. Note that `ethers` is\n# used for sourcing gas estimates, and it can supply a default value of\n# 1.5 Gwei for priority fees. This is notably seen on Optimism (chainId\n# 10), and can lead to overpriced transactions. Operators are encouraged\n# to tune these scalers to meet their own needs and risk profile.\nMAX_FEE_PER_GAS_SCALER_10=1.2\nPRIORITY_FEE_SCALER_10=0.1\n\n#### Do not change the configs below without checking with the Across team #####\n#### Or unless you strongly know what you're doing\n\n# A Redis in-memory DB can drastically speed up the performance\n# of the bot. This is technically not required, but reduces the\n# instance of repeated network queries and therefore reduces\n# the time and network bandwidth required for successful relay\n# bot operation.\n# Install redis and then ensure that redis-server is started:\n#     https://redis.io/docs/getting-started/\n# Under the hood, the relayer will cache JSON-rpc request data\n# from requests like `eth_getBlock` in the Redis DB.\nREDIS_URL=\"redis://127.0.0.1:6379\""
            },
            {
                "id": "4b949e1b930049f4bfd6af7f72fd5e0e",
                "code": "# The NODE_MAX_CONCURRENCY environment variable controls the\n# maximum number of concurrent requests can be issued to a\n# single RPC provider. Per-chain overrides are possible by\n# appending _<chainID>=<value>. In the event that rate-limiting\n# is occurring (429 responses to RPC requests) then concurrency\n# can be reduced as an alternative to upgrading the RPC provider\n# subscription/quota. In the example below, the global default\n# is set to 25, and is overridden to 40 for Ethereum.\nNODE_MAX_CONCURRENCY=25\nNODE_MAX_CONCURRENCY_1=40\n\n# The relayer can be configured to require a minimum return on\n# capital outlaid when filling relays. This minimum return is\n# specified as a multiplier of the amount to be allocated to each\n# fill. Minimum fees can also be configured per token(symbol)/route\n# combination. Examples:\n# Require 1 bps as the global default (unless overridden).\nMIN_RELAYER_FEE_PCT=0.0001\n# Override: Require at least 1.5 bps on USDC from Arbitrum to Ethereum.\nMIN_RELAYER_FEE_PCT_USDC_42161_1=0.00015\n# Override: Require at least 0.8 bps on WETH from Optimism to Arbitrum.\nMIN_RELAYER_FEE_PCT_WETH_10_42161=0.00008\n\n# The caching duration for a subset of the queries issued to RPC\n# providers can be configured. The default time-to-live (TTL) of\n# queries is 3600 seconds (60 minutes). This is set conservatively to\n# refresh the cache often, so as to ensure that any incomplete or\n# invalid RPC provider responses are ejected within the short term.\n# Increasing cache TTL may improve the speed of the bot and lead to\n# reduced RPC provider quota utilisation, at the cost of increased\n# resource usage (i.e. RAM + disk). Increasing cache TTL may also\n# provide additional exposure to invalid or incomplete RPC responses.\nPROVIDER_CACHE_TTL=3600\n\n# Minimum number of block confirmations (MDC) for a Deposit event\n# before a relay bot will consider the Deposit finalised and\n# valid. The MDC is set based on the total deposit USD volume in a\n# relayer iteration and is specific to an origin chain. For example,\n# if the relayer wants to fill $1000 of deposits originating from mainnet,\n# then it will wait until a deposit is 32 blocks past HEAD before \n# it sends a fill. If the relayer wants to fill $100 of deposits, then it will\n# wait 16 blocks. Users can tweak these settings and take on more finality risk\n# in exchange for reacting to deposits more quickly. The following configuration\n# is equal to the default (i.e. the following config will be used if\n# MIN_DEPOSIT_CONFIRMATIONS is not set. Finality assurances may change over time. \n# See code comments here for more details about the risks with modifying\n# this configuration: https://github.com/across-protocol/relayer-v2/blob/0dde90a5909ce4ddc0dfb27e1ec8bcc1d75e2e25/src/common/Constants.ts#L25\nMIN_DEPOSIT_CONFIRMATIONS='{\"1000\": \"{ \"1\": 32, \"10\": 0, \"137\": 100, \"42161\": 0 }\", \"100\": \"{ \"1\": 16, \"10\": 0, \"137\": 80, \"42161\": 0 }\" }'\n\n# List of tokens that the relayer supports. These are addresses\n# on Ethereum.\n# For example, if only USDC's address is specified, the relayer\n# would only fill transfers of USDC going to any chains (unless\n# overridden by RELAYER_DESTINATION_CHAINS).\n# If RELAYER_TOKENS is not set or set to [], the relayer will fill\n# transfers of any token.\nRELAYER_TOKENS='[\"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\", \"0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48\", \"0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599\"]'\n\n# List of destination chains the relayer supports. If set to a\n# non-empty list, only transfers going to these chains will be\n# filled. In the example below, transfers destined for Ethereum\n# will be ignored.\nRELAYER_DESTINATION_CHAINS='[10,137,42161]'\n\n# By default set to false. If false, the relayer will ignore\n# any deposits that it cannot fully fill. A feature for partial\n# fills is not implemented yet but its possible to do so at the\n# contract level. If this is set to true, then the relayer will\n# fill 1 wei of the deposited amount which will trigger a slow\n# fill payment to be sent from HubPool to SpokePool. There is no\n# benefit to do this, # and the system will function correctly\n# as long as one relayer is sending slow relays. We recommend\n# that you leave this value set to \"false\".\nSEND_SLOW_RELAYS=false\n\n# This inventory config will be explained in a separate section\n# but generally this informs the relayer how it should rebalance\n# token inventories across chains. The following simple example\n# tells the bot that it should target holding 8% of its WETH on\n# chain 10, 8% on chain 42161, 8% on chain 137, 0.2% on chain\n# 288, and the remainder on Mainnet. The config can also be used\n# to specify how much ETH versus WETH to hold.\nRELAYER_INVENTORY_CONFIG='{\"tokenConfig\":{\"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\":{\"1\":{\"targetPct\":100,\"thresholdPct\":100,\"unwrapWethThreshold\":3.5,\"unwrapWethTarget\":5},\"10\":{\"targetPct\":8,\"thresholdPct\":5,\"unwrapWethThreshold\":0.75,\"unwrapWethTarget\":1.5},\"137\":{\"targetPct\":8,\"thresholdPct\":5},\"288\":{\"targetPct\":0.2,\"thresholdPct\":0.1,\"unwrapWethThreshold\":0.65,\"unwrapWethTarget\":1},\"42161\":{\"targetPct\":8,\"thresholdPct\":5,\"unwrapWethThreshold\":0.75,\"unwrapWethTarget\":1.5}}}}'\n\n# Defaults to 1, must be set >= 1. If set > 1, then for any RPC\n# request, this requires that at least this count of RPCs\n# specified in the NODE_URLS_[ID] list return the exact same\n# response. We recommend setting this to 2 so that the relayer\n# does not accidentally relay a deposit whose properties two\n# different RPCs disagree about. This edge case is rare but\n# could lead to loss of funds.\nNODE_QUORUM=1"
            },
            {
                "id": "4e45d704b80b4aada64a9ae3973b88c7",
                "code": "\"RELAYER_INVENTORY_CONFIG\": {\n  \"tokenConfig\": {\n     \"0xC02aaA39b223FE8D0A0e5C4F27eAD9083C756Cc2\": {\n        \"1\": { \"targetPct\": 100, \"thresholdPct\": 100, \"unwrapWethThreshold\": 3.5, \"unwrapWethTarget\": 5 },\n        \"10\": { \"targetPct\": 8, \"thresholdPct\": 5, \"unwrapWethThreshold\": 0.75, \"unwrapWethTarget\": 1.5 },\n        \"137\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"288\": { \"targetPct\": 0.2, \"thresholdPct\": 0.1, \"unwrapWethThreshold\": 0.65, \"unwrapWethTarget\": 1 },\n        \"42161\": { \"targetPct\": 8, \"thresholdPct\": 5, \"unwrapWethThreshold\": 0.75, \"unwrapWethTarget\": 1.5 }\n      },\n      \"0x6B175474E89094C44Da98b954EedeAC495271d0F\": {\n        \"10\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"137\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"288\": { \"targetPct\": 0.2, \"thresholdPct\": 0.1 },\n        \"42161\": { \"targetPct\": 8, \"thresholdPct\": 5 }\n      },\n      \"0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48\": {\n        \"10\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"137\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"288\": { \"targetPct\": 0.2, \"thresholdPct\": 0.1 },\n        \"42161\": { \"targetPct\": 8, \"thresholdPct\": 5 }\n      },\n      \"0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599\": {\n        \"10\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"137\": { \"targetPct\": 8, \"thresholdPct\": 5 },\n        \"288\": { \"targetPct\": 0.2, \"thresholdPct\": 0.1 },\n        \"42161\": { \"targetPct\": 8, \"thresholdPct\": 5 }\n      }\n  },\n  \"wrapEtherThreshold\": 2\n}"
            },
            {
                "id": "cf6697ff83bd4b0ebe6a3691fd5073e7",
                "code": "# Run the relayer, deriving private key from the SECRET env var (default)\nSEND_RELAYS=false yarn relay\n\n# Run the relayer, overriding the private key source.\n# Sub in the desired key source (secret, mnemonic, privateKey, gckms).\nSEND_RELAYS=false yarn relay --wallet <secret|mnemonic|privateKey|gckms>"
            },
            {
                "id": "5864bb542d9c4b92a5256c38a0f6d89c",
                "code": "[debug]: {\n  \"at\": \"Relayer#index\",\n  \"message\": \"End of serverless execution loop - terminating process\"\n}"
            }
        ]
    },
    "https://docs.across.to/developer-docs/developers/integrating-across-into-your-application": {
        "title": "Integrating Across into your application | Across Docs",
        "headers": [
            "Integrating Across into your application",
            "How to initiate a deposit",
            "How to track a deposit",
            "How to speed up a deposit that is taking a long time to be picked up by a relayer",
            "Using the API versus SDK to construct deposit parameters",
            "Commonly asked questions"
        ],
        "paragraphs": [
            "Instructions and examples for calling the smart contract functions that would allow third party projects to transfer assets across EVM networks.",
            "Across was designed as a platform on which third party projects enabling cross chain asset transfer could be built. We are very excited to build together and we've put together this guide which should contain everything you need to integrate with Across.",
            "If you have further questions or suggestions for this guide, please send a message to the #developer-questions channel in the Across Discord.",
            "Deposits are initiated from contracts called \"SpokePools\" deployed on any supported EVM. For example, on Ethereum the contract is named \"Ethereum_SpokePool.sol\"_, and on Optimism the contract is named \"Optimism_SpokePool.sol\".",
            "Spoke pool addresses can be found here.",
            "Deposits are triggered via the SpokePool contract's deposit function, whose parameters are explained in detail here. This documentation also explains how to populate parameters like relayerFeePct and quoteTime.",
            "Here is a deposit sent on Optimism. Here is a deposit on Ethereum",
            "Deposit and corresponding fill events are conveniently scraped by a database and displayed here.",
            "The database implementation can be found in this repository.",
            "The lower a deposit's relayer fee %, the less relayers are incentivized to fulfill it. While a deposit is not fully filled, its relayer fee % can be increased by calling speedUpDeposit.",
            "We recommend using the API for the easiest way to query suggested deposit params.",
            "Can I use the Across SDK to submit contract transactions?",
            "Not yet, working on it!",
            "Last updated 1 year ago"
        ],
        "lists": [
            "How to initiate a deposit\nHow to track a deposit\nHow to speed up a deposit that is taking a long time to be picked up by a relayer\nUsing the API versus SDK to construct deposit parameters\nCommonly asked questions",
            "Can I use the \nAcross SDK\n to submit contract transactions?\nNot yet, working on it!",
            "Not yet, working on it!"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/composable-bridging": {
        "title": "Composable Bridging | Across Docs",
        "headers": [
            "Composable Bridging",
            "What is Composable Bridging:?",
            "How does it work? ",
            "Requirements ",
            "Detailed instructions",
            "Example: Implementing a Bridge and Unwrap"
        ],
        "paragraphs": [
            "Use Across to bridge + execute a transaction",
            "You can instruct Across to execute a transaction upon filling your deposit on the destination chain. This transaction would be executed atomically with the fill transaction.",
            "NOTE: The transaction that gets executed on the destination chain must be non-reverting otherwise user deposits may risk getting locked.",
            "When a relayer fills your deposit by calling fillRelay() on the destination SpokePool, if the deposit has a message attached, then the SpokePool will attempt to call handleAcrossMessage() on your recipient address and pass in the following params: ",
            "handleAcrossMessage(address tokenSent, uint256 amount, bool fillCompleted, address relayer, bytes memory message)",
            "The deposit message is not empty",
            "The recipient address is a contract on the destinationChainId that implements a public handleAcrossMessage(address,uint256,bool,address,bytes) function, and this function must be non-reverting ",
            "The additional gas cost to execute the above function is compensated for in the deposit's relayerFeePct",
            "Construct your message ",
            "Use the Across API to get an estimate of the relayerFeePct you should set for your message and recipient combination ",
            "Call deposit() passing in your message ",
            "Once the relayer calls fillRelay() on the destination, your recipient's handleAcrossMessage will be executed",
            "Imagine that I want to bridge ETH from Ethereum to Optimism and receive ETH, not wrapped WETH on Optimism",
            "I will deploy the following contract on Optimism which unwraps received WETH into ETH and sends to a designated owner EOA",
            "Call Across-API’s /suggested-fees endpoint with params ?token=0xWETH-on-ethereum-address&destinationChainId=10&amount= x&originChainId=1&recipient=MyUnwrapper.address&message=0x1234 ",
            "Here we set message to something useless but not-zero so that the destination SpokePool ultimately calls handleAcrossMessage on MyUnwrapper",
            "Last updated 1 year ago"
        ],
        "lists": [
            "What is Composable Bridging:?\nHow does it work? \nRequirements \nDetailed instructions\nExample: Implementing a Bridge and Unwrap",
            "handleAcrossMessage(address tokenSent, uint256 amount, bool fillCompleted, address relayer, bytes memory message)",
            "The deposit \nmessage\n is not empty\nThe \nrecipient\n address is a contract on the destinationChainId that implements a public \nhandleAcrossMessage(address,uint256,bool,address,bytes) \nfunction, and this function must be non-reverting \nThe additional gas cost to execute the above function is compensated for in the deposit's \nrelayerFeePct",
            "Construct your \nmessage\n \nUse the Across API to get an estimate of the \nrelayerFeePct\n you should set for your message and recipient combination \nCall \ndeposit()\n passing in your message \nOnce the relayer calls \nfillRelay()\n on the destination, your recipient's \nhandleAcrossMessage\n will be executed",
            "Imagine that I want to bridge ETH from Ethereum to Optimism and receive ETH, not wrapped WETH on Optimism\nI will deploy the following contract on Optimism which unwraps received WETH into ETH and sends to a designated \nowner\n EOA",
            "Call Across-API’s \n/suggested-fees\n endpoint with params \n?token=0xWETH-on-ethereum-address&destinationChainId=10&amount= x&originChainId=1&recipient=\nMyUnwrapper\n.address&message=0x1234 \nHere we set \nmessage\n to something useless but not-zero so that the destination \nSpokePool\n ultimately calls \nhandleAcrossMessage\n on \nMyUnwrapper"
        ],
        "tables": [],
        "code_blocks": [
            {
                "id": "f8d5fd41629345d08d789926234ecc93",
                "code": "contract MyUnwrapper {\n    WETHInterface weth;\n    addess payable owner;\n    constructor() public {\n        owner = msg.sender;\n    }\n    function handleAcrossMessage(\n        address tokenSent, \n        uint256 amount, \n        bool, // fillCompleted unused\n        address, // relayer is unused \n        bytes memory // message is unused\n    ) external { \n        require(tokenSent == address(weth), \"received token not WETH\");\n        weth.withdraw(amount);\n        (bool sent, bytes memory data) = owner.call{value: amount}(\"\");\n        require(sent, \"Failed to send Ether\");\n    } \n}"
            }
        ]
    },
    "https://docs.across.to/developer-docs/developers/developer-notes": {
        "title": "Developer notes | Across Docs",
        "headers": [
            "Developer notes",
            "ETH/WETH Behavior",
            "More questions?"
        ],
        "paragraphs": [
            "This page includes a running list of Across behaviors that developers who are using Across should be aware of:",
            "Across liquidity pools are filled using WETH but, depending on the context, Across will sometimes send a user ETH and sometimes send a user WETH.",
            "If a bridge transfer is being sent to an EOA, the EOA will receive ETH (not WETH)",
            "If a bridge transfer is being sent to a contract, the contract will receive WETH (not ETH)",
            "If you are a developer working on integrating your project with Across, please reach out to us on Discord!",
            "We look forward to helping you integrate with the best bridge around!",
            "Last updated 1 year ago"
        ],
        "lists": [
            "ETH/WETH Behavior\nMore questions?",
            "If a bridge transfer is being sent to an EOA, \nthe EOA will receive ETH\n (not WETH)\nIf a bridge transfer is being sent to a contract, \nthe contract will receive WETH\n (not ETH)"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/developers/migration-from-v2-to-v3": {
        "title": "Migration from V2 to V3 | Across Docs",
        "headers": [
            "Across API migration guide",
            "Overview",
            "Non-breaking changes",
            "Breaking changes (mid- to long-term)",
            "Breaking Change: Across+ (Composable Bridging) ",
            "Events",
            "Important changes for dApp Developers"
        ],
        "paragraphs": [
            "Information for users of the Across API and the smart contracts (e.g. those who call the Across SpokePools directly to deposit or fill bridge transfers and those who track SpokePool events).",
            "Across V2 is migrating in-place to V3 and will support cross-chain token swaps and a more streamlined contract interface. This guide is intended to help developers who integrate with Across to prepare their codebases for the upgrade. Please note that this page is a work in progress, and more sections will be added to help with different types of integrations.",
            "Across v3 redesigns how fees are handled when creating deposits. In a nutshell, the calculation of fees will be simplified and replaced byinputAmount/outputAmount arguments. This will impact the response data of the API and also how to call the deposit function of a SpokePool contract. Note that these changes won't be breaking short-term but are actionable mid- to long-term.",
            "For a seamless upgrade, there will be no breaking changes for the existing v2 interfaces.",
            "In Across v2, the request GET /suggested-fees returned",
            "It was then expected to call the method deposit of a SpokePool like",
            "The lpFeePct was not required as an argument and automatically derived based on the quoteTimestamp. But if you wanted to show the total bridge fee to the user, then you would have to sum them up like",
            "In Across v3, we need to pass the lpFeePct as part of the total fee when calling the deposit function. In order to be backwards-compatible, the API now returns for GET /suggested-fees",
            "There are no changes to the interface and therefore no changes are required for how you call the deposit function or calculate the total bridge fee. If you want to show the correct fee breakdown though, some changes are needed (see here).",
            "If you want to show the correct detailed fee breakdown, you can use the newly added v3 properties of the GET /suggested-fees response data",
            "Using the values of the new fees struct, you need to call the deposit function like",
            "Even though there are no actionable changes short-term, some change will be actionable mid- to long-term.",
            "The v2 deposit function will be deprecated and replaced by the depositV3 function. This new function has a different signature and does not expect a relayFeePct. Instead it requires an outputAmount",
            "In order to set the correct outputAmount, the caller needs to send a request GET /suggested-fees and subtract the returned fees from the inputAmount like",
            "As described here, the v3 fees have a different structure now. Eventually the redundant fields capitalFeePct, capitalFeeTotal, relayGasFeePct, relayGasFeeTotal and lpFeePct will be removed",
            "All users of Across+ (Composable Bridging) are required to upgrade their messaging implementations to use handleV3AcrossMessage().",
            "Across v3 updates the callback interface for receiving messages in a recipient contract. The new function prototype is as follows:",
            " The key differences to Across v2 are:",
            "handleAcrossMessage() -> handleV3AcrossMessage",
            "Function parameter `bool fillCompleted` has been removed.",
            "For a smooth transition to Across v3, integrators are recommended to implement concurrent support for handleAcrossMessage() and handleV3AcrossMessage(). handleAcrossMessage() can be removed at a later date.",
            "The motivation for updating the function prototype is that partial fills are no longer possible in Across v3, so messaging recipients no longer require special logic to account for them.",
            "If you depend on querying SpokePool events to track the status of bridge transfers, then this section is designed to support you.",
            "In Across V2, a bridge consists of a FundsDeposited event on the origin chain and a FilledRelay event on the destination chain. They must match on all common parameters and the FilledRelay#realizedLpFeePct must be equal to the LP fee at the FundsDeposited#quoteTimestamp based on the computation rules described in the UMIP. Moreover, the FilledRelay#destinationToken also needs to match the FundsDeposited#originToken based on the matching rules described in the UMIP.",
            "Across V3 bridge transfers consist of a V3FundsDeposited event emitted on the origin chain and a FilledV3Relay event emitted on the destination chain.",
            "V3FundsDeposited and FilledV3Relay must match on all common parameters except for outputToken. This can be set to 0x0 (the zero address) at deposit time to signal to relayers that they should use the \"equivalent\" token on the destinationChainId to fill the deposit, therefore if V3FundsDeposited#outputToken == 0x0 then FilledV3Relay#outputToken must be equal to the \"equivalent\" token on the destination chain. The Across UMIP should be updated to explain what it means to be \"equivalent\" but this essentially means the output and input token map to the same token on Ethereum, for example they could be the different USDC addresses on different L2s.",
            "Note that the amount transferred to the recipient is relayExecutionInfo.updatedOutputAmount",
            "All deposits emitted in V3 contracts will be V3FundsDeposited events which can only be filled via SpokePool#filledV3Relay.",
            "The important changes here are:",
            "realizedLpFeePct The relayer no longer needs to set the realizedLpFeePct as a parameter when calling the fill function. LP fees will still be charged to relayers at refund time (i.e. they will receive the inputAmount minus the LP fees) and these fees will still be computed using the formula in the UMIP based on the deposit.quoteTimestamp. This is a nice quality of life improvement for relayers who will still need to compute the LP fee for a deposit but can use a much wider margin of error, as this fee will only be important for computing their profitability and they will not be at risk of sending an invalid fill if this fee is off by a small amount.",
            "outputToken: See the section above about how outputToken must be set if FundsDeposited#outputToken == 0x0. This should be set to the \"equivalent\" token for the destination chain in this case.",
            "No partial fills: it is not possible to send partial fills in V3.",
            "Slow fills: Slow fills will be requested via a new function requestSlowFill. Slow fills can only be requested on deposits where the inputToken and outputToken are \"equivalent\". Slow fills will pay out the inputAmount * realizedLpFeePct, which will be set as the slow fill's updatedOutputAmount",
            "The deposit interface will not change. The function will however emit a new event V3FundsDeposited as outlined in Across V3 Events. The fillDeadline will be set to MAX_UINT, meaning that the deposit will never expire and be refunded to the origin chain. The outputToken will be set to 0x0 to signal to depositors that the \"equivalent\" output token should be replaced at fill time. The exclusivityDeadline and exclusiveRelayer will be set to 0 and 0x0 respectively suggesting that there is no exclusivity period. Finally, the outputAmount will be equal to  inputAmount * (1 - relayerFeePct).",
            "To speed up a deposit, a new function will need to be used. Previously this was named speedUpDeposit and the new function to speed up a V3FundsDeposited event will be speedUpV3Deposit.",
            "Last updated 11 months ago"
        ],
        "lists": [
            "handleAcrossMessage() -> handleV3AcrossMessage\nFunction parameter `bool fillCompleted` has been removed.",
            "realizedLpFeePct\n The relayer no longer needs to set the \nrealizedLpFeePct\n as a parameter when calling the fill function. LP fees will still be charged to relayers at refund time (i.e. they will receive the inputAmount minus the LP fees) and these fees will still be computed using the formula in the UMIP based on the \ndeposit.quoteTimestamp.\n This is a nice quality of life improvement for relayers who will still need to compute the LP fee for a deposit but can use a much wider margin of error, as this fee will only be important for computing their profitability and they will not be at risk of sending an invalid fill if this fee is off by a small amount.\noutputToken:\n See the section above about how \noutputToken\n must be set if FundsDeposited#outputToken == 0x0. This should be set to the \"equivalent\" token for the destination chain in this case.\nNo partial fills: it is not possible to send partial fills in V3.\nSlow fills: Slow fills will be requested via a new function \nrequestSlowFill\n. Slow fills can only be requested on deposits where the \ninputToken\n and \noutputToken\n are \"equivalent\". Slow fills will pay out the \ninputAmount * realizedLpFeePct\n, which will be set as the slow fill's \nupdatedOutputAmount"
        ],
        "tables": [],
        "code_blocks": [
            {
                "id": "IiFyj7Qx7yhj",
                "code": "type FeesResponse = {\n    // ... other fields\n    capitalFeePct: string;\n    capitalFeeTotal: string;\n    relayGasFeePct: string;\n    relayGasFeeTotal: string;\n    relayFeePct: string; // capitalFeePct + gasFeePct\n    relayFeeTotal: string; // capitalFeeTotal + gasFeeTotal\n    lpFeePct: string;\n}"
            },
            {
                "id": "cbjHyM7Puxz1",
                "code": "const tx = await spokePool.deposit(\n    // ... other args\n    feesResponse.relayFeePct // capitalFeePct + gasFeePct\n)"
            },
            {
                "id": "3FkIhESjSYq0",
                "code": "const totalBridgeFeePct =  relayFeePct + lpFeePct"
            },
            {
                "id": "uOYuu19QpkfW",
                "code": "type FeesResponse = {\n    // ... other fields\n    capitalFeePct: string;\n    capitalFeeTotal: string;\n    relayGasFeePct: string;\n    relayGasFeeTotal: string;\n-   relayFeePct: string; // capitalFeePct + gasFeePct\n+   relayFeePct: string; // capitalFeePct + gasFeePct + lpFeePct\n-   relayFeeTotal: string; // capitalFeeTotal + gasFeeTotal\n+   relayFeeTotal: string; // capitalFeeTotal + gasFeeTotal + lpFeeTotal\n-   lpFeePct: string;\n+   lpFeePct: \"0\";\n}"
            },
            {
                "id": "6TtJcoZZfVTW",
                "code": "type FeesResponse = {\n     // ... other fields\n+    totalRelayFee: { // relayerCapitalFee + relayerGasFee + lpFee\n+        pct: string;\n+        total: string;\n+    };\n+    relayerCapitalFee: {\n+        pct: string;\n+        total: string;\n+    };\n+    relayerGasFee: {\n+        pct: string;\n+        total: string;\n+    };\n+    lpFee: {\n+        pct: string;\n+        total: string;\n+    };\n}"
            },
            {
                "id": "WBTAlCPIyHEY",
                "code": "const tx = await spokePool.deposit(\n    // ... other args\n    feesResponse.totalRelayFee.pct\n)"
            },
            {
                "id": "WrZVJsN5C7dH",
                "code": "function depositV3(\n    address depositor,\n    address recipient,\n    address inputToken,\n    address outputToken,\n    uint256 inputAmount,\n    uint256 outputAmount, // <-- replaces fees\n    uint256 destinationChainId,\n    address exclusiveRelayer,\n    uint32 quoteTimestamp,\n    uint32 fillDeadline,\n    uint32 exclusivityDeadline,\n    bytes calldata message\n) public payable"
            },
            {
                "id": "LMn9flMzFvwT",
                "code": "// Assuming inputToken equals outputToken\nconst outputAmount = inputAmount - feesResponse.totalRelayFee.total\nconst tx = await spokePool.depositV3(\n    // ... other args\n    outputAmount\n)"
            },
            {
                "id": "O5KsT1gT3xr7",
                "code": "type FeesResponse = {\n    // ... other fields\n-    capitalFeePct: string;\n-    capitalFeeTotal: string;\n-    relayGasFeePct: string;\n-    relayGasFeeTotal: string;\n-    relayFeePct: string; // capitalFeePct + gasFeePct\n-    relayFeeTotal: string; // capitalFeeTotal + gasFeeTotal\n-    lpFeePct: string;\n+    totalRelayFee: { // relayerCapitalFee + relayerGasFee + lpFee\n+        pct: string;\n+        total: string;\n+    };\n+    relayerCapitalFee: {\n+        pct: string;\n+        total: string;\n+    };\n+    relayerGasFee: {\n+        pct: string;\n+        total: string;\n+    };\n+    lpFee: {\n+        pct: string;\n+        total: string;\n+    };\n}"
            },
            {
                "id": "NIZ1bfn9gmp4",
                "code": "function handleV3AcrossMessage(\n    address tokenSent,\n    uint256 amount,\n    address relayer,\n    bytes memory message\n) external;"
            },
            {
                "id": "yXEcd0DUJesw",
                "code": "event FundsDeposited(\n    uint256 amount,\n    uint256 originChainId,\n    uint256 indexed destinationChainId,\n    int64 relayerFeePct,\n    uint32 indexed depositId,\n    uint32 quoteTimestamp,\n    address originToken,\n    address recipient,\n    address indexed depositor,\n    bytes message\n)\n\nevent FilledRelay(\n    uint256 amount,\n    uint256 totalFilledAmount,\n    uint256 fillAmount,\n    uint256 repaymentChainId,\n    uint256 indexed originChainId,\n    uint256 destinationChainId,\n    int64 relayerFeePct,\n    int64 realizedLpFeePct,\n    uint32 indexed depositId,\n    address destinationToken,\n    address relayer,\n    address indexed depositor,\n    address recipient,\n    bytes message,\n    RelayExecutionInfo updatableRelayData\n)\n\nstruct RelayExecutionInfo {\n    address recipient;\n    bytes message;\n    int64 relayerFeePct;\n    bool isSlowRelay;\n    int256 payoutAdjustmentPct;\n}"
            },
            {
                "id": "7vjuXkI6xEPh",
                "code": "// Fill type is emitted in the FilledRelay event to assist Dataworker with determining which types of\n// fills to refund (e.g. only fast fills) and whether a fast fill created a sow fill excess.\nenum FillType {\n    FastFill,\n    // Fast fills are normal fills that do not replace a slow fill request.\n    ReplacedSlowFill,\n    // Replaced slow fills are fast fills that replace a slow fill request. This type is used by the Dataworker\n    // to know when to send excess funds from the SpokePool to the HubPool because they can no longer be used\n    // for a slow fill execution.\n    SlowFill\n    // Slow fills are requested via requestSlowFill and executed by executeSlowRelayLeaf after a bundle containing\n    // the slow fill is validated.\n}\n\n struct V3RelayExecutionEventInfo {\n    address updatedRecipient;\n    bytes updatedMessage;\n    uint256 updatedOutputAmount;\n    FillType fillType;\n}\n\nevent V3FundsDeposited(\n    address inputToken,\n    address outputToken,\n    uint256 inputAmount,\n    uint256 outputAmount,\n    uint256 indexed destinationChainId,\n    uint32 indexed depositId,\n    uint32 quoteTimestamp,\n    uint32 fillDeadline,\n    uint32 exclusivityDeadline,\n    address indexed depositor,\n    address recipient,\n    address exclusiveRelayer,\n    bytes message\n);\n\nevent FilledV3Relay(\n    address inputToken,\n    address outputToken,\n    uint256 inputAmount,\n    uint256 outputAmount,\n    uint256 repaymentChainId,\n    uint256 indexed originChainId,\n    uint32 indexed depositId,\n    uint32 fillDeadline,\n    uint32 exclusivityDeadline,\n    address exclusiveRelayer,\n    address indexed relayer,\n    address depositor,\n    address recipient,\n    bytes message,\n    V3RelayExecutionEventInfo relayExecutionInfo\n);"
            },
            {
                "id": "y09rr12kHrmS",
                "code": "/**\n * @notice Fulfill request to bridge cross chain by sending specified output tokens to the recipient.\n * @dev The fee paid to relayers and the system should be captured in the spread between output\n * amount and input amount when adjusted to be denominated in the input token. A relayer on the destination\n * chain will send outputAmount of outputTokens to the recipient and receive inputTokens on a repayment\n * chain of their choice. Therefore, the fee should account for destination fee transaction costs, the\n * relayer's opportunity cost of capital while they wait to be refunded following an optimistic challenge\n * window in the HubPool, and a system fee charged to relayers.\n * @dev The hash of the relayData will be used to uniquely identify the deposit to fill, so\n * modifying any params in it will result in a different hash and a different deposit. The hash will comprise\n * all parameters passed to depositV3() on the origin chain along with that chain's chainId(). This chain's\n * chainId() must therefore match the destinationChainId passed into depositV3.\n * Relayers are only refunded for filling deposits with deposit hashes that map exactly to the one emitted by the\n * origin SpokePool therefore the relayer should not modify any params in relayData.\n * @dev Cannot fill more than once. Partial fills are not supported.\n * @param relayData struct containing all the data needed to identify the deposit to be filled. Should match\n * all the same-named parameters emitted in the origin chain V3FundsDeposited event.\n * - depositor: The account credited with the deposit who can request to \"speed up\" this deposit by modifying\n * the output amount, recipient, and message.\n * - recipient The account receiving funds on this chain. Can be an EOA or a contract. If\n * the output token is the wrapped native token for the chain, then the recipient will receive native token if\n * an EOA or wrapped native token if a contract.\n * - inputToken: The token pulled from the caller's account to initiate the deposit. The equivalent of this\n * token on the repayment chain will be sent as a refund to the caller.\n * - outputToken The token that the caller will send to the recipient on the destination chain. Must be an\n * ERC20.\n * - inputAmount: This amount, less a system fee, will be sent to the caller on their repayment chain of choice as a refund\n * following an optimistic challenge window in the HubPool.\n * - outputAmount: The amount of output tokens that the caller will send to the recipient.\n * - originChainId: The origin chain identifier.\n * - exclusiveRelayer The relayer that will be exclusively allowed to fill this deposit before the\n * exclusivity deadline timestamp.\n * - fillDeadline The deadline for the caller to fill the deposit. After this timestamp,\n * the fill will revert on the destination chain.\n * - exclusivityDeadline: The deadline for the exclusive relayer to fill the deposit. After this\n * timestamp, anyone can fill this deposit.\n * - message The message to send to the recipient if the recipient is a contract that implements a\n * handleV3AcrossMessage() public function\n * @param repaymentChainId Chain of SpokePool where relayer wants to be refunded after the challenge window has\n * passed. Will receive inputAmount of the equivalent token to inputToken on the repayment chain.\n */\nfunction fillV3Relay(V3RelayData calldata relayData, uint256 repaymentChainId)\n\n// This struct represents the data to fully specify a **unique** relay submitted on this chain.\n// This data is hashed with the chainId() and saved by the SpokePool to prevent collisions and protect against\n// replay attacks on other chains. If any portion of this data differs, the relay is considered to be\n// completely distinct.\nstruct V3RelayData {\n    // The address that made the deposit on the origin chain.\n    address depositor;\n    // The recipient address on the destination chain.\n    address recipient;\n    // This is the exclusive relayer who can fill the deposit before the exclusivity deadline.\n    address exclusiveRelayer;\n    // Token that is deposited on origin chain by depositor.\n    address inputToken;\n    // Token that is received on destination chain by recipient.\n    address outputToken;\n    // The amount of input token deposited by depositor.\n    uint256 inputAmount;\n    // The amount of output token to be received by recipient.\n    uint256 outputAmount;\n    // Origin chain id.\n    uint256 originChainId;\n    // The id uniquely identifying this deposit on the origin chain.\n    uint32 depositId;\n    // The timestamp on the destination chain after which this deposit can no longer be filled.\n    uint32 fillDeadline;\n    // The timestamp on the destination chain after which any relayer can fill the deposit.\n    uint32 exclusivityDeadline;\n    // Data that is forwarded to the recipient.\n    bytes message;\n}\n\nstruct V3SlowFill {\n    V3RelayData relayData;\n    uint256 chainId;\n    uint256 updatedOutputAmount;\n}"
            },
            {
                "id": "a9U6puWT51qu",
                "code": "function depositV3(\n    address depositor,\n    address recipient,\n    address inputToken,\n    address outputToken,\n    uint256 inputAmount,\n    uint256 outputAmount,\n    uint256 destinationChainId,\n    address exclusiveRelayer,\n    uint32 quoteTimestamp,\n    uint32 fillDeadline,\n    uint32 exclusivityDeadline,\n    bytes calldata message\n) external payable;\n\n// Old function:\nfunction deposit(\n    address recipient,\n    address originToken,\n    uint256 amount,\n    uint256 destinationChainId,\n    int64 relayerFeePct,\n    uint32 quoteTimestamp,\n    bytes memory message,\n    uint256 maxCount\n) external payable;"
            },
            {
                "id": "rRaA1FkpIQp7",
                "code": "function speedUpV3Deposit(\n    address depositor,\n    uint32 depositId,\n    uint256 updatedOutputAmount,\n    address updatedRecipient,\n    bytes calldata updatedMessage,\n    bytes calldata depositorSignature\n) external;\n\n// Old function:\nfunction speedUpDeposit(\n    address depositor,\n    int64 updatedRelayerFeePct,\n    uint32 depositId,\n    address updatedRecipient,\n    bytes memory updatedMessage,\n    bytes memory depositorSignature\n) external;"
            }
        ]
    },
    "https://docs.across.to/developer-docs/additional-info/support-links": {
        "title": "Support Links | Across Docs",
        "headers": [
            "Support Links"
        ],
        "paragraphs": [
            "Across",
            "Twitter",
            "Discord",
            "Medium",
            "Github",
            "Audit report",
            "Last updated 8 months ago"
        ],
        "lists": [
            "Across\nTwitter\nDiscord\nMedium\nGithub\nAudit report"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/additional-info/bug-bounty": {
        "title": "Bug Bounty | Across Docs",
        "headers": [
            "Bounty Program",
            "Submissions",
            "Terms & Conditions"
        ],
        "paragraphs": [
            "Last updated 11 months ago",
            "Security of the platform is our highest priority. All smart contracts and off-chain code (i.e. most of the code within the across-protocol repository) are within scope and are publicly verifiable. Security researchers are eligible for a bug bounty for reporting undiscovered vulnerabilities.",
            "We encourage the community to audit our open source code; we also encourage the responsible disclosure of any issues. The bug bounty program is intended to recognize the value of working with the community of independent security researchers and sets out our definition of good faith in the context of finding and reporting vulnerabilities, as well as what you can expect from us in return.",
            "Across offers substantial rewards for discoveries that can prevent the loss of assets, the freezing of assets, or harm to users.",
            "To be eligible a bounty, a bug must have not been previously known by the Across team or publicly disclosed by anyone. All Across smart contracts and interactions (including bots and front end code) are in scope.",
            "The amount of compensation will vary depending on bug severity. Reward amounts typically correspond to severity in the following manner. The reward currency can be discussed on a case by case basis.",
            "Low",
            "$250",
            "Medium",
            "$1,000",
            "High",
            "$10,000",
            "Critical",
            "up to $1,000,000",
            "Severity is calculated according to the OWASP risk rating model based on Impact and Likelihood.",
            "Please email your submissions to [email protected].",
            "The submission must include clear and concise steps to reproduce the discovered vulnerability. The following layout of the bug bounty report is encouraged:",
            "Description: Describe at a high level the bug with links to problematic code",
            "Attack: Detailed instructions for exploiting the bug",
            "Mitigation: How to resolve the bug",
            "Suggested risk rating: The recommended severity of this bug",
            "The same terms and conditions from the UMA bug bounty program apply here."
        ],
        "lists": [
            "Bounty Program\nSubmissions\nTerms & Conditions",
            "Description: Describe at a high level the bug with links to problematic code\nAttack: Detailed instructions for exploiting the bug\nMitigation: How to resolve the bug\nSuggested risk rating: The recommended severity of this bug"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/additional-info/audits": {
        "title": "Audits | Across Docs",
        "headers": [],
        "paragraphs": [
            "Across Token and Token Distributor Audit",
            "Across V2 Audit",
            "UMA's Continuous Audit (Optimistic Oracle)",
            "UMA Audit – L2 Bridges",
            "UMA Audit – Phase 4",
            "UMA Audit – Phase 6",
            "Last updated 2 years ago"
        ],
        "lists": [
            "Across Token and Token Distributor Audit\nAcross V2 Audit\nUMA's Continuous Audit (Optimistic Oracle)\nUMA Audit – L2 Bridges\nUMA Audit – Phase 4\nUMA Audit – Phase 6"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://www.gitbook.com/?utm_source=content&utm_medium=trademark&utm_campaign=hBVFLntFXCM0TMmhxIGU": {
        "title": "GitBook â Build product documentation your users will love",
        "headers": [
            "Product documentationyour users will love",
            "Publish unbeatable documentation",
            "Better internal docs",
            "Collaborate on docs like you collaborate on code",
            "Smarter, AI-powered documentation",
            "Control access to your published docs",
            "Integrate with your stack",
            "Our customers love GitBook!",
            "Get started for free",
            "Get started for free",
            "Get started for free"
        ],
        "paragraphs": [
            "Docs",
            "",
            "",
            "",
            "Product",
            "Features",
            "Pricing",
            "",
            "",
            "",
            "We're hiring!",
            "Forget building your own custom docs platform. With GitBook you get beautiful documentation for your users, and a branch-based Git workflow for your team.",
            "Sign up with GitHub",
            "Home Hero GitHub CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Sign up with GitHub",
            "Home Hero GitHub CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Sign up with GitHub",
            "Home Hero GitHub CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Start for free",
            "Home Hero CTA",
            "Start for free",
            "sign_up",
            "Start for free",
            "Home Hero CTA",
            "Start for free",
            "sign_up",
            "Start for free",
            "Home Hero CTA",
            "Start for free",
            "sign_up",
            "Published site",
            "GitBook editor",
            "Published site",
            "GitBook editor",
            "Public docs",
            "Effortlessly migrate your product docs to GitBook, customize them to match your brand, then publish them to the world â or just a selected group, if you prefer. Then keep them updated with built-in content insights.",
            "Discover documentation",
            "Home Public Docs Block",
            "Discover Documentation",
            "open_public_docs_website",
            "Discover documentation",
            "Home Public Docs Block",
            "Discover Documentation",
            "open_public_docs_website",
            "Discover documentation",
            "Home Public Docs Block",
            "Discover Documentation",
            "open_public_docs_website",
            "Internal docs",
            "Find the perfect new home for your organizationâs code docs, technical wikis, product plans, API documentation and more. GitBook is flexible, and uses a Git-like branching workflow your team will love.",
            "Learn more",
            "Home Internal Docs Block",
            "Learn More",
            "open_internal_docs_website",
            "Learn more",
            "Home Internal Docs Block",
            "Learn More",
            "open_internal_docs_website",
            "Learn more",
            "Home Internal Docs Block",
            "Learn More",
            "open_internal_docs_website",
            "Git Sync",
            "Sync your docs with a GitHub or GitLab repository and everyone can contribute to your docs, wherever they prefer to work. So your technical writers can use a WYSIWYG editor, while engineers add to your docs directly in Git. And everything stays in sync, with feedback and reviews to guarantee quality.",
            "Discover Git Sync",
            "Home GitSync Block",
            "Tell me more",
            "open_gitsync_website",
            "Discover Git Sync",
            "Home GitSync Block",
            "Tell me more",
            "open_gitsync_website",
            "Discover Git Sync",
            "Home GitSync Block",
            "Tell me more",
            "open_gitsync_website",
            "GitBook AI",
            "Improve your writing with a click. GitBook AI can simplify, shorten, or translate any text you want â or even just write a first draft for you. And because GitBook AI is trained on your docs, you can ask it a question and get the answer you need instantly. And so can your users.",
            "Explore GitBook AI",
            "Home GitBook AI Block",
            "Explore GitBook AI",
            "open_gitbook_ai_website",
            "Explore GitBook AI",
            "Home GitBook AI Block",
            "Explore GitBook AI",
            "open_gitbook_ai_website",
            "Explore GitBook AI",
            "Home GitBook AI Block",
            "Explore GitBook AI",
            "open_gitbook_ai_website",
            "Visitor authentication",
            "Choose who can access your documentation. With visitor authentication, you can keep sensitive information away from competitors and hackers. So only your chosen customers, team members or authorized users can view your docs.",
            "Find out more",
            "Home VA Block",
            "Find out more",
            "open_va_website",
            "Find out more",
            "Home VA Block",
            "Find out more",
            "open_va_website",
            "Find out more",
            "Home VA Block",
            "Find out more",
            "open_va_website",
            "Integrations",
            "Install one of our verified integrations, or build your own with our API. Because a great knowledge management system should work with everything you use on a daily basis.",
            "See our integrations",
            "Home Integrations Block",
            "See our integrations",
            "open_integrations_website",
            "See our integrations",
            "Home Integrations Block",
            "See our integrations",
            "open_integrations_website",
            "See our integrations",
            "Home Integrations Block",
            "See our integrations",
            "open_integrations_website",
            "\"GitBook is uniquely designed to serve both as an internal wiki and as a source for easily editable public docs â all backed by change requests, custom domain configuration, and git. This combination really differentiates the tool and has been super helpful to our team.\"",
            "Billy Daly",
            "\"GitBook is uniquely designed to serve both as an internal wiki and as a source for easily editable public docs â all backed by change requests, custom domain configuration, and git. This combination really differentiates the tool and has been super helpful to our team.\"",
            "Billy Daly",
            "\"GitBook is uniquely designed to serve both as an internal wiki and as a source for easily editable public docs â all backed by change requests, custom domain configuration, and git. This combination really differentiates the tool and has been super helpful to our team.\"",
            "Billy Daly",
            "EliÃ©cer HernÃ¡ndez",
            "We use Gitbook at our startup to write useful and easy-to-digest documentation. It is the only platform that provides so much flexibility for this.",
            "EliÃ©cer HernÃ¡ndez",
            "We use Gitbook at our startup to write useful and easy-to-digest documentation. It is the only platform that provides so much flexibility for this.",
            "EliÃ©cer HernÃ¡ndez",
            "We use Gitbook at our startup to write useful and easy-to-digest documentation. It is the only platform that provides so much flexibility for this.",
            "Austin Hamrick",
            "GitBook is a great source for handbooks, manuals, and other documents for online resources.",
            "Austin Hamrick",
            "GitBook is a great source for handbooks, manuals, and other documents for online resources.",
            "Austin Hamrick",
            "GitBook is a great source for handbooks, manuals, and other documents for online resources.",
            "Shubhendu Shubham",
            "Now @GitBook supports AI based summaries and search from your documentation. One of the best documentation tools for developers & open source enthusiasts.",
            "Shubhendu Shubham",
            "Now @GitBook supports AI based summaries and search from your documentation. One of the best documentation tools for developers & open source enthusiasts.",
            "Shubhendu Shubham",
            "Now @GitBook supports AI based summaries and search from your documentation. One of the best documentation tools for developers & open source enthusiasts.",
            "Lane Fox",
            "I build software tools and use GitBook for documentation. It's amazing, I recommend it to all of my colleagues doing similar work. I honestly don't know what I would do without it.",
            "Lane Fox",
            "I build software tools and use GitBook for documentation. It's amazing, I recommend it to all of my colleagues doing similar work. I honestly don't know what I would do without it.",
            "Lane Fox",
            "I build software tools and use GitBook for documentation. It's amazing, I recommend it to all of my colleagues doing similar work. I honestly don't know what I would do without it.",
            "Sewell Stephens",
            "I would definately recommend Gitbook. I've used it for a while and it works great.",
            "Sewell Stephens",
            "I would definately recommend Gitbook. I've used it for a while and it works great.",
            "Sewell Stephens",
            "I would definately recommend Gitbook. I've used it for a while and it works great.",
            "Elme Dela Rosa",
            "My portfolio is on GitBook! Love how versatile and flexible this app is. highly recommended.",
            "Elme Dela Rosa",
            "My portfolio is on GitBook! Love how versatile and flexible this app is. highly recommended.",
            "Elme Dela Rosa",
            "My portfolio is on GitBook! Love how versatile and flexible this app is. highly recommended.",
            "Vlad A. Ionescu",
            "We switched to @GitBook (git-powered documentation hosting) a while back and so far we're really, really happy with it. More people need to know about this amazing service!",
            "Vlad A. Ionescu",
            "We switched to @GitBook (git-powered documentation hosting) a while back and so far we're really, really happy with it. More people need to know about this amazing service!",
            "Vlad A. Ionescu",
            "We switched to @GitBook (git-powered documentation hosting) a while back and so far we're really, really happy with it. More people need to know about this amazing service!",
            "Illia Berestovskyi",
            "I enjoy the product. GitBook became the one-place tool for all documentation of our product.",
            "Illia Berestovskyi",
            "I enjoy the product. GitBook became the one-place tool for all documentation of our product.",
            "Illia Berestovskyi",
            "I enjoy the product. GitBook became the one-place tool for all documentation of our product.",
            "Rob Hussey",
            "I use GitBook in all my apps for self-serve knowledge base/help docs.",
            "Rob Hussey",
            "I use GitBook in all my apps for self-serve knowledge base/help docs.",
            "Rob Hussey",
            "I use GitBook in all my apps for self-serve knowledge base/help docs.",
            "Noj Vek",
            "Was comparing @GitBook with @NotionHQ, I think GitBook wins hands down in its offering. Its focused, the UI is clean, fast and very user friendly. (Personal Notes | KnowledgeBase | Product Docs). Makes sense that it has 500k users. Love the product.",
            "Noj Vek",
            "Was comparing @GitBook with @NotionHQ, I think GitBook wins hands down in its offering. Its focused, the UI is clean, fast and very user friendly. (Personal Notes | KnowledgeBase | Product Docs). Makes sense that it has 500k users. Love the product.",
            "Noj Vek",
            "Was comparing @GitBook with @NotionHQ, I think GitBook wins hands down in its offering. Its focused, the UI is clean, fast and very user friendly. (Personal Notes | KnowledgeBase | Product Docs). Makes sense that it has 500k users. Love the product.",
            "Play around with GitBook and set up your docs for free.  Add your team and pay when youâre ready.",
            "Sign up with GitHub",
            "Footer CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Start for free",
            "Footer CTA",
            "Start for free",
            "sign_up",
            "Play around with GitBook and set up your docs for free.  Add your team and pay when youâre ready.",
            "Sign up with GitHub",
            "Footer CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Start for free",
            "Footer CTA",
            "Start for free",
            "sign_up",
            "Play around with GitBook and set up your docs for free.  Add your team and pay when youâre ready.",
            "Sign up with GitHub",
            "Footer CTA",
            "Sign up with GitHub",
            "sign_up_github",
            "Start for free",
            "Footer CTA",
            "Start for free",
            "sign_up",
            "Public docs",
            "",
            "",
            "",
            "API docs",
            "",
            "",
            "",
            "Internal docs",
            "",
            "",
            "",
            "Enterprise",
            "",
            "",
            "",
            "Open source",
            "",
            "",
            "",
            "Customer showcase",
            "",
            "",
            "",
            "Product tour",
            "",
            "",
            "",
            "Pricing",
            "",
            "",
            "",
            "Visitor authentication",
            "",
            "",
            "",
            "Git Sync",
            "",
            "",
            "",
            "GitBook AI",
            "",
            "",
            "",
            "Integrations",
            "",
            "",
            "",
            "GitBook product docs",
            "",
            "",
            "",
            "GitBook developer docs",
            "",
            "",
            "",
            "Blog",
            "",
            "",
            "",
            "Videos",
            "",
            "",
            "",
            "Events",
            "",
            "",
            "",
            "Changelog",
            "",
            "",
            "",
            "Security and compliance",
            "",
            "",
            "",
            "Newsletter",
            "",
            "",
            "",
            "About",
            "",
            "",
            "",
            "Careers",
            "",
            "",
            "",
            "Contact and support",
            "",
            "",
            "",
            "Terms of service",
            "",
            "",
            "",
            "Privacy policy",
            "",
            "",
            "",
            "Â© 2025 Copyright GitBook INC. 440 N Barranca Ave #7171, Covina, CA 91723, USA. EIN: 320502699",
            "Public docs",
            "",
            "",
            "",
            "API docs",
            "",
            "",
            "",
            "Internal docs",
            "",
            "",
            "",
            "Enterprise",
            "",
            "",
            "",
            "Open source",
            "",
            "",
            "",
            "Customer showcase",
            "",
            "",
            "",
            "Product tour",
            "",
            "",
            "",
            "Pricing",
            "",
            "",
            "",
            "Visitor authentication",
            "",
            "",
            "",
            "Git Sync",
            "",
            "",
            "",
            "GitBook AI",
            "",
            "",
            "",
            "Integrations",
            "",
            "",
            "",
            "GitBook product docs",
            "",
            "",
            "",
            "GitBook developer docs",
            "",
            "",
            "",
            "Blog",
            "",
            "",
            "",
            "Videos",
            "",
            "",
            "",
            "Events",
            "",
            "",
            "",
            "Changelog",
            "",
            "",
            "",
            "Security and compliance",
            "",
            "",
            "",
            "Newsletter",
            "",
            "",
            "",
            "About",
            "",
            "",
            "",
            "Careers",
            "",
            "",
            "",
            "Contact and support",
            "",
            "",
            "",
            "Terms of service",
            "",
            "",
            "",
            "Privacy policy",
            "",
            "",
            "",
            "Â© 2025 Copyright GitBook INC. 440 N Barranca Ave #7171, Covina, CA 91723, USA. EIN: 320502699",
            "Public docs",
            "",
            "",
            "",
            "API docs",
            "",
            "",
            "",
            "Internal docs",
            "",
            "",
            "",
            "Enterprise",
            "",
            "",
            "",
            "Open source",
            "",
            "",
            "",
            "Customer showcase",
            "",
            "",
            "",
            "Product tour",
            "",
            "",
            "",
            "Pricing",
            "",
            "",
            "",
            "Visitor authentication",
            "",
            "",
            "",
            "Git Sync",
            "",
            "",
            "",
            "GitBook AI",
            "",
            "",
            "",
            "Integrations",
            "",
            "",
            "",
            "GitBook product docs",
            "",
            "",
            "",
            "GitBook developer docs",
            "",
            "",
            "",
            "Blog",
            "",
            "",
            "",
            "Videos",
            "",
            "",
            "",
            "Events",
            "",
            "",
            "",
            "Changelog",
            "",
            "",
            "",
            "Security and compliance",
            "",
            "",
            "",
            "Newsletter",
            "",
            "",
            "",
            "About",
            "",
            "",
            "",
            "Careers",
            "",
            "",
            "",
            "Contact and support",
            "",
            "",
            "",
            "Terms of service",
            "",
            "",
            "",
            "Privacy policy",
            "",
            "",
            "",
            "Â© 2025 Copyright GitBook INC. 440 N Barranca Ave #7171, Covina, CA 91723, USA. EIN: 320502699"
        ],
        "lists": [
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs/how-across-works": {
        "title": "Overview | Across Docs",
        "headers": [],
        "paragraphs": [],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://github.com/UMAprotocol/UMIPs/blob/master/UMIPs/umip-157.md": {
        "title": "UMIPs/UMIPs/umip-157.md at master · UMAprotocol/UMIPs · GitHub",
        "headers": [
            "Navigation Menu",
            "Search code, repositories, users, issues, pull requests...",
            "\n        Provide feedback\n      ",
            "\n        Saved searches\n      ",
            "Use saved searches to filter your results more quickly",
            "Files",
            "Breadcrumbs",
            "umip-157.md",
            "Latest commit",
            "History",
            "Breadcrumbs",
            "umip-157.md",
            "File metadata and controls",
            "Headers",
            "Note",
            "Summary",
            "Across V2 Architecture",
            "Motivation",
            "Data Specifications and Implementation",
            "Definitions",
            "Comparing events chronologically",
            "Valid bundle proposals",
            "Comparing deposit events chronologically for different origin chains",
            "Matching L1 tokens to Running Balances or Net Send Amounts",
            "Versions",
            "Ancillary Data Specifications",
            "Configuration Constants",
            "Global Constants",
            "Token Constants",
            "Preliminary Information",
            "Proposal Information",
            "Determining block range for root bundle proposal",
            "Finding Valid Relays",
            "Matching L2 tokens and L1 tokens",
            "Validating realizedLpFeePct",
            "Finding Slow Relays",
            "Computing Slow Relay payment amounts",
            "Constructing the PoolRebalanceRoot",
            "Constructing RelayerRefundRoot",
            "Constructing SlowRelayRoot",
            "Determing the Result",
            "Footer",
            "Footer navigation"
        ],
        "paragraphs": [
            "We read every piece of feedback, and take your input very seriously.",
            "\n            To see all available qualifiers, see our documentation.\n          ",
            "Unless otherwise specified in UMIP-179, this UMIP is superseded by UMIP-179.",
            "The DVM should support the ACROSS-V2 price identifier.",
            "The basic architecture of Across V2 is a single LP (\"Liquidity Provider\") pool sitting on Ethereum mainnet connected to many \"spoke pools\" deployed on\nvarious chains to facilitate user \"deposits\". A deposit is a cross-chain transfer request from an \"origin\" chain to a different \"destination\" chain, which is fulfilled when a \"relayer\" sends the depositor their desired transfer amount (less fees) on their desired destination chain.",
            "If there is no relayer who can provide all the capital for a given deposit request, a \"slow relay\" (or \"slow fill\") is performed where the funds are sent from the\nLP pool to the destination spoke to fulfill the deposit. These slow fill requests are also included in the aforementioned bundles.",
            "Bundles are implemented on-chain as Merkle Roots which uniquely identify the set of all repayments and rebalance instructions over a specific block range. Therefore, Across V2 moves capital to repay relayers and fulfil bridge requests through periodic bundles, all validated by the OO.",
            "This UMIP explains exactly how to construct and verify a bundle.",
            "",
            "The ACROSS-V2 price identifier is intended to be used by the Across v2 contracts to verify whether a bundle of bridge-related\ntransactions submitted to mainnet is valid.",
            "Note 1: the following details will often refer to the Across V2 repo\nat commit hash: a8ab11fef3d15604c46bba6439291432db17e745. This allows the UMIP to have a constant reference rather than\ndepending on a changing repository.",
            "Note 2: when referencing \"later\" or \"earlier\" events, the primary sort should be on the block number, the secondary\nsort should be on the transactionIndex, and the tertiary sort should be on the logIndex. See the section on comparing events for more details.",
            "Note 3: wherever unspecified, sorting should be ascending by default, not descending.",
            "Note 4: all event data should be identically returned by at least two independent, reputable RPC providers to give confidence in the integrity of the data.",
            "Smart contract transactions can emit events that conform to the specifications described in the \"Returns\" section of these docs. Specifically, an event is expected to have a unique combination of blockNumber, transactionIndex and logIndex. To compare events e1 and e2 chronologically, we can say\nthat e1 is \"earlier\" than e2 if e1.blockNumber < e2.blockNumber OR if e1.blockNumber == e2.blockNumber && e1.transactionIndex < e2.transactionIndex OR if e1.blockNumber == e2.blockNumber && e1.transactionIndex == e2.transactionIndex && e1.logIndex < e2.logIndex.",
            "So, \"earlier\" events have a lower block number, transaction index, or log index, and we should compare event properties in that order.",
            "A root bundle can be proposed by calling HubPool.proposeRootBundle(), which will will emit a ProposedRootBundle event.",
            "The root bundle is valid once all of its PoolRebalanceLeaves are executed via HubPool.executeRootBundle(), which can only be called after the proposed root bundle's challengePeriodEndTimestamp is passed.",
            "Each deposit emits a quoteTimestamp parameter. This timestamp should be evaluated within the context of the Ethereum network, and should be mapped to the Ethereum block who's timestamp is closest to the deposit.quoteTimestamp but not greater (i.e. block.timestamp closest to and <= deposit.quoteTimestamp).",
            "The RootBundleExecuted event and [PoolRebalanceLeaf] structure both contain equal length arrays: l1Tokens, netSendAmounts, bundleLpFees, and runningBalances. Each l1Token value in l1Tokens is an address correspondingto an ERC20 token deployed on Ethereum Mainnet. It should be mapped to the value in any of the other three arrays (netSendAmounts, bundleLpFees, and runningBalances) that shares the same index within the array.",
            "For example, if l1Tokens is \"[0x123,0x456,0x789]\" and netSendAmounts is \"[1,2,3]\", then the \"net send amount\" for token with address \"0x456\" is equal to \"2\".",
            "The ancillary data only needs a single field: ooRequester, which should be the contract requesting the price from the\nOO. Because that contract should contain enough information about the request for voters to resolve the validity of the\nrelay, no additional ancillary data is needed.",
            "Example:",
            "The following constants should reflect what is stored in the AcrossConfigStore contract deployed on Etherscan. This contract is owned by Across governance and acts as the source of truth for the following variables. The global variables currently stored in the above contract for this UMIP are:",
            "To query the value for any of the above constants, the AcrossConfigStore contract's globalConfig(bytes32) function should be called with the hex value of the variable name. For example, the \"MAX_POOL_REBALANCE_LEAF_SIZE\" can be queried by calling globalConfig(toHex(\"MAX_POOL_REBALANCE_LEAF_SIZE\")) which is equivalent to globalConfig(\"0x4d41585f504f4f4c5f524542414c414e43455f4c4541465f53495a45\"). For example, this might return",
            "\"25\"",
            "The following constants are also stored in the AcrossConfigStore contract but are specific to an Ethereum token address. Therefore, they are fetched by querying the config store's tokenConfig(address) function.",
            "For example, querying tokenConfig(\"0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2\") might return:",
            "\"{\"rateModel\":{\"UBar\":\"750000000000000000\",\"R0\":\"50000000000000000\",\"R1\":\"0\",\"R2\":\"600000000000000000\"},\"spokeTargetBalances\":{\"1\":{\"threshold\":\"200000000000000000000\",\"target\":\"100000000000000000000\"},\"42161\":{\"threshold\":\"400000000000000000000\",\"target\":\"200000000000000000000\"}}}\"",
            "This UMIP will explain later how global and token-specific configuration settings are used.",
            "The ooRequester address is expected to be an instance of the\nHubPool contract.",
            "If any of the expected details in the ooRequester are not available in the expected form because the HubPool does not\nmatch the expected interface, the identifier should return 0.",
            "To get the proposal data, the voter should find events that match\nthis signature\non the ooRequester. The event that describes this proposal is the matching event with the highest block number whose\ntimestamp is less than or equal to the timestamp of the price request. If there are two matching events that both\nsatisfy this criteria, then it can be resolved in one of two ways. If the timestamp matches the request timestamp,\nthen the earlier event is the one to be\nused. If the timestamp is earlier than the request timestamp, the later event should be used.",
            "From the selected event, one should be able to glean the following information:",
            "The bundleEvaluationBlockNumbers is an ordered array of end block numbers for each destination chain for this bundle. Which index\ncorresponds to which chain is denoted by the \"CHAIN_ID_INDICES\" in the global config.",
            "To determine the start block number for each chainId, search for the latest\nRootBundleExecuted event\nwith a matching chainId while still being earlier than the timestamp of the request. Once that event is found, search\nfor the\nProposeRootBundle\nevent that is as late as possible, but earlier than the RootBundleExecuted event we just identified. Once this proposal event is found, determine its\nmapping of indices to chainId in its bundleEvaluationBlockNumbers array using \"CHAIN_ID_INDICES\". For\neach chainId, their starting block number is the minimum of that chain's bundleEvaluationBlockNumber + 1 in this previous valid proposal event and the latest block height for the chain.",
            "Using the minimum allows the block range to handle the edge case where a chain has not advanced its block height since the last proposal, for example when a chain is undergoing a known hard fork.",
            "Use this mechanism to determine the starting block numbers for each chainId represented in the original\nbundleEvaluationBlockNumbers.",
            "Note that the above rules require that the bundleEvaluationBlockNumbers for each chainId are greater than or equal to the preceding valid proposal's bundleEvaluationBlockNumbers for the same chainId. In the normal case where the chain has not paused and is producing blocks at a normal frequency, the block range for each proposal starts at the preceding proposal's bundleEvaluationBlockNumbers plus 1 and go to the next bundleEvaluationBlockNumbers. In the case where the latest block height hasn't advanced beyond the previous bundleEvaluationBlockNumber, then the block range for the proposal will go from the preceding proposal's bundleEvaluationBlockNumbers to the same number, i.e. block ranges of 0.",
            "Note also that the above rules for determining an end block don't apply if the chain ID is in the \"DISABLED_CHAINS\" list. if a chain exists in DISABLED_CHAINS, the proposed bundle must reuse the bundle end block from the last valid proposal before it was added. Specifically, if a chain exists in DISABLED_CHAINS at the \"mainnet\" end block (chain ID 1) for a particular proposal, the end block for that chain should be identical to its value in the latest executed bundle.",
            "For each destination chain, find all\nFilledRelay events\non its SpokePool between the starting block number and ending block number for that chain. For this query, exclude\nany FilledRelay events that have isSlowRelay set to true or have fillAmount equal to 0.",
            "Note: in the sections below, if the relay is considered to be invalid at any point, that relay must not be considered\nwhen constructing the bundle.",
            "For each FilledRelay event found earlier, a\nFundsDeposited\nevent should be found in one of the spoke pools for the originChainId where the following parameters match:",
            "Additionally, matching relays should have their destinationToken set such that the following process is satisfied:",
            "To determine the validity of the realizedLPFeePct in the FilledRelay event, the exact same process is used as in\nthe identifier IS_RELAY_VALID, specified in UMIP 136. However, instead ofing a RateModelStore contract to look up a deposit's rate model, we can use the AcrossConfigStore's tokenConfig to look up the rate model for a deposit. The deposited originToken can be mapped to an l1Token by following step 2 above which can be used to query a rateModel.",
            "Moreover, instead of calling liquidityUtilizationCurrent and\nliquidityUtilizationPostRelay on the BridgePool contract (passing no arguments) to compute the rate model, identically-named methods would be\ncalled on the HubPool contract, passing in a single argument, the l1Token derived in the 3 step process above.",
            "If the realizedLPFeePct that is computed using those means does not match the realizedLPFeePct in the\nFilledRelay event, then the relay is considered invalid.",
            "All valid FilledRelay events should then be stored for the construction of the bundle.",
            "To determine all slow relays, follow the following process:",
            "For all remaining groups, they should be stored in a list of slow relay groups.",
            "For a given slow relay identified above, we can compute the associated deposit's \"unfilled amount\" as deposit.amount - latestFill.totalFilledAmount, where latestFill is the last fill chronologically for a deposit. Since each fill increments totalFilledAmount, the latestFill can also be identified by sorting all fills associated wiht a deposit and keeping the fill with the largest totalFilledAmount.",
            "Note: Since  we eliminated all fills where totalFilledAmount == deposit.amount, the remaining \"last fill\" should have totalFilledAmount < deposit.amount AND have totalFilledAmount > [all other fills for deposit].totaFilledAmount.",
            "To construct the poolRebalanceRoot, you need to form a list of rebalances.",
            "For all valid FilledRelay events above, group them by repaymentChainId and their associated l1Token found above.",
            "For each group, sum the fillAmount values to get the total relay repayments for that group.",
            "Similarly, sum the fillAmount * realizedLPFeePct / 1e18 to get the total LP fees for that group.",
            "To determine the amount to modify the running balances:",
            "We now need to add the preceding running balance value to the current one for a given repaymentChainId and l1Token.\nFor each repaymentChainId and l1Token combination, older\nRootBundleExecuted events\nshould be queried to find the preceding RootBundleExecuted event. This means identifying the most recent RootBundleExecuted event with a chainId matching the repaymentChainId and identifying the runningBalanceValue at the index of the l1Token.",
            "For each tuple of l1Token and repaymentChainId, we should have computed a total running balance value. The\nfollowing algorithm describes the process of computing running balance and net send amount:",
            "Take the above running balances and net send amounts and group them by only repaymentChainId and sort by repaymentChainId. Within\neach group, sort by l1Token. If there are more than MAX_POOL_REBALANCE_LEAF_SIZE l1Tokens, a particular chain's leaf will\nneed to be broken up into multiple leaves, starting at groupIndex 0 and each subsequent leaf incrementing the\ngroupIndex value by 1.",
            "Now that we have ordered leaves, we can assign each one a unique leafId starting from 0.",
            "With all of that information, each leaf should be possible to construct in the format given\nhere.\nImportantly, the l1Tokens, bundleLpFees, netSendAmounts and runningBalances arrays should all be the same length. The latter three arrays are values mapped to the l1Tokens entry of the same index. See this section to better explain how to map l1Tokens to the other three arrays.",
            "Once the leaves are constructed, the merkle root can be constructed by hashing each leaf data structure using\nSolidity's standard process of keccak256(abi.encode(poolRebalanceLeaf)). Once the leaves are hashed, the tree should\nbe constructed in the standard way such that it is verifyable using\nOpenZeppelin's MerkleProof\nlibrary. See examples here\nfor how to construct these types of trees.",
            "In the previous section, groups of relays were found for each destinationChainId and l1Token. Then, the rebalance\nparameters were determined for each group. All FillRelay events found for a particular destinationChainId and\nl1Token that were found in the previous section that also have isSlowRelay set to false will be referred to as\n\"fast relays\" in this section. For each destinationChainId and l1Token grouping in the previous section, a net send\namount was found. This value will be used in this section as well.",
            "For each group from the previous section defined by a destinationChainId and l1Token that either a) has fast relays\nor b) has a negative net send amount, a RelayerRefundRoot must be constructed. The data structure is shown\nhere.\nOne or more (in the case of leafs with more than MAX_RELAYER_REPAYMENT_LEAF_SIZE refunds) RelayerRefundLeaf will be\nconstructed for each of these applicable groups. The following defines how to construct each of these leaves given the\ninformation about each group determined in the previous section.",
            "The amountToReturn should be set to max(-netSendAmount, 0).",
            "The l2TokenAddress is the corresponding L2 token address for the l1Token in the previous section. Note: see above section for how to map L1 and L2 tokens via events on L1. This mapping should be done according to the highest\nquoteTimestamp of any relays in the group. If no relays are present, then as of the previous successful proposal.",
            "refundAmounts and refundAddresses are just computed by grouping the relays in this group by the relayer and\nsumming the amount - (amount * lpFeePct / 1e18) for each relay. These should be sorted in descending order of\nrefundAmounts. If two refundAmounts are equal, then they should be sorted by relayer address.",
            "If there are more than MAX_RELAYER_REPAYMENT_LEAF_SIZE refundAddresses for a particular l2TokenAddress then\nthese should be split up into MAX_RELAYER_REPAYMENT_LEAF_SIZE element leaves (sorted as described above) with only\nthe first leaf for a particular l2TokenAddress able to contain a nonzero amountToReturn.",
            "Once these are computed for all relays, the leaves (or groups of leaves for > 25 elements) should be sorted by\nchainId as the primary index, then l2TokenAddress as the secondary index, and then the individual sorting\nof > MAX_RELAYER_REPAYMENT_LEAF_SIZE element groups as the tertiary sorting. Once these are sorted, each leaf can be\ngiven a leafId based on its index in the group, starting at 0.",
            "Once these leaves are constructed, they can be used to form a merkle root as described in the previous section.",
            "To construct the SlowRelayRoot leaves as described\nhere,\njust form leaves based on all the slow relays found in the \"Finding Slow Relays\" section above. The information in the\nrelays should map directly to the leaf data structure.",
            "Their primary sorting index should be originChainId and the secondary sorting index should be depositId.",
            "You can then construct a merkle root similar to how it's done in the previous two sections.",
            "Three conditions must be met for the proposal to be deemed valid:",
            "If the proposal is deemed invalid, return 0. If valid, return 1. Note: these values are scaled by 1e18."
        ],
        "lists": [
            "GitHub Copilot\n\n        Write better code with AI\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity\n\n        Find and fix vulnerabilities\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActions\n\n        Automate any workflow\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodespaces\n\n        Instant dev environments\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIssues\n\n        Plan and track work\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Review\n\n        Manage code changes\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussions\n\n        Collaborate outside of code\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Search\n\n        Find more, search less",
            "All features\n\n    \n\n\n\n\n\n\n      Documentation\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      GitHub Skills\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Blog",
            "Enterprises\n\n    \n\n\n\n\n\n\n      Small and medium teams\n\n    \n\n\n\n\n\n\n      Startups\n\n    \n\n\n\n\n\n\n      Nonprofits",
            "DevSecOps\n\n    \n\n\n\n\n\n\n      DevOps\n\n    \n\n\n\n\n\n\n      CI/CD\n\n    \n\n\n\n\n\n\n      View all use cases",
            "Healthcare\n\n    \n\n\n\n\n\n\n      Financial services\n\n    \n\n\n\n\n\n\n      Manufacturing\n\n    \n\n\n\n\n\n\n      Government\n\n    \n\n\n\n\n\n\n      View all industries",
            "AI\n\n    \n\n\n\n\n\n\n      DevOps\n\n    \n\n\n\n\n\n\n      Security\n\n    \n\n\n\n\n\n\n      Software Development\n\n    \n\n\n\n\n\n\n      View all",
            "Learning Pathways\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      White papers, Ebooks, Webinars\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Customer Stories\n\n    \n\n\n\n\n\n\n      Partners\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Executive Insights",
            "GitHub Sponsors\n\n        Fund open source developers",
            "The ReadME Project\n\n        GitHub community articles",
            "Topics\n\n    \n\n\n\n\n\n\n      Trending\n\n    \n\n\n\n\n\n\n      Collections",
            "Enterprise platform\n\n        AI-powered developer platform",
            "Advanced Security\n\n        Enterprise-grade security features\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Copilot\n\n        Enterprise-grade AI features\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPremium Support\n\n        Enterprise-grade 24/7 support",
            "",
            "Notifications\n\n \nYou must be signed in to change notification settings\n\n\n\n\n\n\n \n\n\n\n\nFork\n    \n104\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n          Star\n\n \n62",
            "Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIssues\n\n\n1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPull requests\n\n\n4\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjects\n\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights",
            "Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Issues\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Pull requests\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Actions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Security\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Insights",
            "Preview\nCode\nBlame",
            "\"MAX_POOL_REBALANCE_LEAF_SIZE\"\n\n\n\"MAX_RELAYER_REPAYMENT_LEAF_SIZE\"\n\n\n\"VERSION\"\n\n\n\nAcross protocol version number. Supporting implementations should query this value against the value defined in their implementation to determine compatibility with the current protocol version. Failure to correctly evaluate the version number may mean that filled relays are not refunded from the HubPool, and may therefore result in loss of funds. For more information go \nhere\n.\n\n\n\n\n\n\n\"DISABLED_CHAINS\"\n\n\n\nThis must be a stringified list of chain ID numbers. This cannot contain the chain ID \"1\", or the HubPool chain ID. Chains in here must be contained in \nCHAIN_ID_INDICES\n.\n\n\n\n\n\n\n\"CHAIN_ID_INDICES\"\n\n\n\nThis should default to the value [1,10,137,288,42161] for any blocks older than the first time that this global variable was published. This is to account for the initial version of this UMIP which defined this ID list in the UMIP rather than in the ConfigStore contract. Chains can only be added to this list to be valid.",
            "Across protocol version number. Supporting implementations should query this value against the value defined in their implementation to determine compatibility with the current protocol version. Failure to correctly evaluate the version number may mean that filled relays are not refunded from the HubPool, and may therefore result in loss of funds. For more information go \nhere\n.",
            "This must be a stringified list of chain ID numbers. This cannot contain the chain ID \"1\", or the HubPool chain ID. Chains in here must be contained in \nCHAIN_ID_INDICES\n.",
            "This should default to the value [1,10,137,288,42161] for any blocks older than the first time that this global variable was published. This is to account for the initial version of this UMIP which defined this ID list in the UMIP rather than in the ConfigStore contract. Chains can only be added to this list to be valid.",
            "\"rateModel\"\n\n\n\nThis is a JSON struct of rate model parameters.\n\n\nThese parameters should fully specify the rate model for this token as described in\n\nUMIP 136\n.\n\n\nEach field in this struct should be an integer represented as a string (to allow unlimited precision).\n\n\nThe rateModel struct is only valid if it contains all of the following parameters: \nUBar\n, \nR0\n, \nR1\n, and \nR2\n.\n\n\n\n\n\n\n\"routeRateModel\"\n\n\n\nSimilar to \nrateModel\n, this is a dictionary of \noriginChain-destinationChain\n keys mapped to rate models that take precedence over the \nrateModel\n for a token on that specific deposit route. The route rate models should follow the same \nUBar\n, \nR0\n, \nR1\n, \nR2\n format as the default \nrateModel\n\n\n\n\n\n\n\"spokeTargetBalances\"\n\n\n\nThis is contains a JSON mapping from chainId to JSON structs.\n\n\nEach struct contains two sub-fields, \"target\" and \"threshold\".\n\n\nEach is an integer represented as a string (to allow unlimited precision).\n\n\nThese integers should both be positive values. If either is negative, it should be treated as \"0\" when used.\n\n\nThe \"target\" integer should be < the \"threshold\" integer. If not, the \"theshold\" integer should be treated as if\nit contained the same value as the \"target\" integer when used.\n\n\nIf \"spokeTargetBalances\", a particular chainId is missing from the mapping, or \"target\" or \"threshold\" is missing,\nthe missing \"target\" and \"threshold\" should be defaulted to 0.",
            "This is a JSON struct of rate model parameters.\n\n\nThese parameters should fully specify the rate model for this token as described in\n\nUMIP 136\n.\n\n\nEach field in this struct should be an integer represented as a string (to allow unlimited precision).\n\n\nThe rateModel struct is only valid if it contains all of the following parameters: \nUBar\n, \nR0\n, \nR1\n, and \nR2\n.",
            "Similar to \nrateModel\n, this is a dictionary of \noriginChain-destinationChain\n keys mapped to rate models that take precedence over the \nrateModel\n for a token on that specific deposit route. The route rate models should follow the same \nUBar\n, \nR0\n, \nR1\n, \nR2\n format as the default \nrateModel",
            "This is contains a JSON mapping from chainId to JSON structs.\n\n\nEach struct contains two sub-fields, \"target\" and \"threshold\".\n\n\nEach is an integer represented as a string (to allow unlimited precision).\n\n\nThese integers should both be positive values. If either is negative, it should be treated as \"0\" when used.\n\n\nThe \"target\" integer should be < the \"threshold\" integer. If not, the \"theshold\" integer should be treated as if\nit contained the same value as the \"target\" integer when used.\n\n\nIf \"spokeTargetBalances\", a particular chainId is missing from the mapping, or \"target\" or \"threshold\" is missing,\nthe missing \"target\" and \"threshold\" should be defaulted to 0.",
            "bundleEvaluationBlockNumbers\n\n\npoolRebalanceRoot\n\n\nrelayerRefundRoot\n\n\nslowRelayRoot",
            "amount\n\n\noriginChainId\n\n\ndestinationChainId\n\n\nrelayerFeePct\n\n\ndepositId\n\n\nrecipient\n\n\ndepositor",
            "Terms\n\n\n\n\n\n\nPrivacy\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\nStatus\n\n\n\n\n\n\nDocs\n\n\n\n\n\n\nContact\n\n\n\n\n\n\n\n\n\n      Manage cookies\n    \n\n\n\n\n\n\n\n\n\n\n\n      Do not share my personal information"
        ],
        "tables": [
            [
                [
                    "UMIP-157",
                    ""
                ],
                [
                    "UMIP Title",
                    "Add ACROSS-V2 as a supported price identifier"
                ],
                [
                    "Authors",
                    "Matt Rice"
                ],
                [
                    "Status",
                    "Deprecated (See UMIP-179 for Across v3)"
                ],
                [
                    "Created",
                    "03/30/2022"
                ],
                [
                    "Discourse Link",
                    ""
                ]
            ]
        ],
        "code_blocks": []
    },
    "https://docs.across.to/developer-docs#resources-to-learn-more": {
        "title": "Overview | Across Docs",
        "headers": [
            "Overview"
        ],
        "paragraphs": [
            "Below is an overview of how a bridge transfer on Across works from start to finish.",
            "Last updated 11 months ago",
            "A user that would like to move funds from chain A to chain B deposits funds into a Spoke Pool on chain A with instructions about where they would like their funds to wind up and the fee that they are willing to pay.",
            "After the relayer has performed the relay, a proof of that relay and the validity of the original deposit is submitted to the optimistic oracle (OO) and the relayer is reimbursed once this information has been verified by the OO.",
            "The relayer's reimbursement is taken out of a single liquidity pool on Ethereum Mainnet escrowed in a contract called the Hub Pool. Liquidity providers (\"LP's\") to this pool also earn a fee per transfer that is assessed on the user's deposited amount.",
            "The rules for how funds are moved between the L2 Spoke Pools and the L1 Hub Pool to reimburse relayers are explained in UMIP-157. Anyone who wants to move funds between the pools must submit a valid proof to the OO that abides by the rules explained in the UMIP.",
            "To see how this all comes together, check out the chart below showing a complete end-to-end flow of the process.",
            "The smart contract code can be found here, including implementations of the HubPool and SpokePool.",
            "The smart contracts were audited by OpenZeppelin. The audit report contains a high-level summary of how the smart contract architecture works.",
            "Moreover, here is a 60-minute explainer video of the smart contract architecture. Slides for the explainer video can be found here."
        ],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://github.com/across-protocol/contracts-v2": {
        "title": "GitHub - across-protocol/contracts: Smart contracts for Across protocol",
        "headers": [
            "Navigation Menu",
            "Search code, repositories, users, issues, pull requests...",
            "\n        Provide feedback\n      ",
            "\n        Saved searches\n      ",
            "Use saved searches to filter your results more quickly",
            "License",
            "across-protocol/contracts",
            "Folders and files",
            "Latest commit",
            "History",
            "Repository files navigation",
            "Deployed Contract Versions",
            "Requirements",
            "Build",
            "Test",
            "Lint",
            "Deploy and Verify",
            "Tasks",
            "Slither",
            "ZK Sync Adapter",
            "Compile",
            "License",
            "About",
            "License",
            "Stars",
            "Watchers",
            "Forks",
            "\nReleases\n      82",
            "\nPackages\n      0",
            "\nUsed by 127 ",
            "\nContributors\n      17",
            "Languages",
            "Footer",
            "Footer navigation"
        ],
        "paragraphs": [
            "We read every piece of feedback, and take your input very seriously.",
            "\n            To see all available qualifiers, see our documentation.\n          ",
            "\n        Smart contracts for Across protocol\n      ",
            "",
            "Contains smart contract suite to enable instant token transfers between any two networks. Relays are backstopped by\nliquidity held in a central HubPool on Ethereum, which also serves as the cross-chain administrator of all contracts in the\nsystem. SpokePool contracts are deployed to any network that wants to originate token deposits or be the final\ndestination for token transfers, and they are all governed by the HubPool on Ethereum.",
            "This contract set is the second iteration of the Across smart contracts\nwhich facilitate token transfers from any L2 to L1.",
            "These contracts were audited by OpenZeppelin which is a great resource for understanding the contracts.",
            "This video is also useful for understanding the technical architecture.",
            "The latest contract deployments on Production will always be under the deployed tag.",
            "This repository assumes you have Node installed, with a minimum version of 16.18.0. Depending on what you want to do with the repo you might also need foundry and anchor to also be installed. If you have build issues please insure these are both installed first.",
            "Note if you get build issues on the initial yarn command try downgrading to node 20.17 (nvm use 20.17). If you've never used anchor before you might need to run avm use latest as well.",
            "Slither is a Solidity static analysis framework written in Python 3. It runs a\nsuite of vulnerability detectors, prints visual information about contract details, and provides an API to easily write\ncustom analyses. Slither enables developers to find vulnerabilities, enhance their code comprehension, and quickly\nprototype custom analyses.",
            "You can replace SpokePool.sol with the specific contract you want to analyze.",
            "These are special instructions for compiling and deploying contracts on zksync. The compile command will create artifacts-zk and cache-zk directories.",
            "This step requires Docker Desktop to be running, as the solc docker image is fetched as a prerequisite.",
            "yarn compile-zksync",
            "All code in this repository is licensed under BUSL-1.1 unless specified differently in the file.\nIndividual exceptions to this license can be made by Risk Labs, which holds the rights to this\nsoftware and design. If you are interested in using the code or designs in a derivative work,\nfeel free to reach out to licensing@risklabs.foundation.",
            "\n        Smart contracts for Across protocol\n      "
        ],
        "lists": [
            "GitHub Copilot\n\n        Write better code with AI\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity\n\n        Find and fix vulnerabilities\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActions\n\n        Automate any workflow\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCodespaces\n\n        Instant dev environments\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIssues\n\n        Plan and track work\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Review\n\n        Manage code changes\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscussions\n\n        Collaborate outside of code\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode Search\n\n        Find more, search less",
            "All features\n\n    \n\n\n\n\n\n\n      Documentation\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      GitHub Skills\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Blog",
            "Enterprises\n\n    \n\n\n\n\n\n\n      Small and medium teams\n\n    \n\n\n\n\n\n\n      Startups\n\n    \n\n\n\n\n\n\n      Nonprofits",
            "DevSecOps\n\n    \n\n\n\n\n\n\n      DevOps\n\n    \n\n\n\n\n\n\n      CI/CD\n\n    \n\n\n\n\n\n\n      View all use cases",
            "Healthcare\n\n    \n\n\n\n\n\n\n      Financial services\n\n    \n\n\n\n\n\n\n      Manufacturing\n\n    \n\n\n\n\n\n\n      Government\n\n    \n\n\n\n\n\n\n      View all industries",
            "AI\n\n    \n\n\n\n\n\n\n      DevOps\n\n    \n\n\n\n\n\n\n      Security\n\n    \n\n\n\n\n\n\n      Software Development\n\n    \n\n\n\n\n\n\n      View all",
            "Learning Pathways\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      White papers, Ebooks, Webinars\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Customer Stories\n\n    \n\n\n\n\n\n\n      Partners\n\n    \n\n\n\n\n\n\n\n\n\n\n\n      Executive Insights",
            "GitHub Sponsors\n\n        Fund open source developers",
            "The ReadME Project\n\n        GitHub community articles",
            "Topics\n\n    \n\n\n\n\n\n\n      Trending\n\n    \n\n\n\n\n\n\n      Collections",
            "Enterprise platform\n\n        AI-powered developer platform",
            "Advanced Security\n\n        Enterprise-grade security features\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGitHub Copilot\n\n        Enterprise-grade AI features\n      \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPremium Support\n\n        Enterprise-grade 24/7 support",
            "",
            "Notifications\n\n \nYou must be signed in to change notification settings\n\n\n\n\n\n\n \n\n\n\n\nFork\n    \n56\n\n\n\n\n\n\n\n\n\n\n \n\n\n\n\n\n          Star\n\n \n105",
            "Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIssues\n\n\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPull requests\n\n\n38\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nActions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjects\n\n\n0\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInsights",
            "Code\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Issues\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Pull requests\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Actions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Projects\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Security\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n          Insights",
            "README\nLicense",
            "",
            "",
            "TypeScript\n\n\n55.7%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSolidity\n\n\n36.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRust\n\n\n7.5%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOther\n\n\n0.3%",
            "Terms\n\n\n\n\n\n\nPrivacy\n\n\n\n\n\n\nSecurity\n\n\n\n\n\n\nStatus\n\n\n\n\n\n\nDocs\n\n\n\n\n\n\nContact\n\n\n\n\n\n\n\n\n\n      Manage cookies\n    \n\n\n\n\n\n\n\n\n\n\n\n      Do not share my personal information"
        ],
        "tables": [
            [
                [
                    "Name",
                    "Name",
                    "Last commit message",
                    "Last commit date"
                ],
                [
                    "Latest commit History681 Commits"
                ],
                [
                    ".github/workflows",
                    ".github/workflows",
                    "",
                    ""
                ],
                [
                    ".upgradable",
                    ".upgradable",
                    "",
                    ""
                ],
                [
                    "broadcast/DeployPermissionSplitterProxy.s.sol/1",
                    "broadcast/DeployPermissionSplitterProxy.s.sol/1",
                    "",
                    ""
                ],
                [
                    "contracts",
                    "contracts",
                    "",
                    ""
                ],
                [
                    "deploy",
                    "deploy",
                    "",
                    ""
                ],
                [
                    "deployments",
                    "deployments",
                    "",
                    ""
                ],
                [
                    "lib",
                    "lib",
                    "",
                    ""
                ],
                [
                    "programs",
                    "programs",
                    "",
                    ""
                ],
                [
                    "script",
                    "script",
                    "",
                    ""
                ],
                [
                    "scripts",
                    "scripts",
                    "",
                    ""
                ],
                [
                    "src",
                    "src",
                    "",
                    ""
                ],
                [
                    "storage-layouts",
                    "storage-layouts",
                    "",
                    ""
                ],
                [
                    "tasks",
                    "tasks",
                    "",
                    ""
                ],
                [
                    "test",
                    "test",
                    "",
                    ""
                ],
                [
                    "utils",
                    "utils",
                    "",
                    ""
                ],
                [
                    ".eslintignore",
                    ".eslintignore",
                    "",
                    ""
                ],
                [
                    ".eslintrc.js",
                    ".eslintrc.js",
                    "",
                    ""
                ],
                [
                    ".gitignore",
                    ".gitignore",
                    "",
                    ""
                ],
                [
                    ".gitmodules",
                    ".gitmodules",
                    "",
                    ""
                ],
                [
                    ".npmignore",
                    ".npmignore",
                    "",
                    ""
                ],
                [
                    ".prettierignore",
                    ".prettierignore",
                    "",
                    ""
                ],
                [
                    ".prettierrc",
                    ".prettierrc",
                    "",
                    ""
                ],
                [
                    ".rustfmt.toml",
                    ".rustfmt.toml",
                    "",
                    ""
                ],
                [
                    ".solhint.json",
                    ".solhint.json",
                    "",
                    ""
                ],
                [
                    ".solhintignore",
                    ".solhintignore",
                    "",
                    ""
                ],
                [
                    "Anchor.toml",
                    "Anchor.toml",
                    "",
                    ""
                ],
                [
                    "CODEOWNERS",
                    "CODEOWNERS",
                    "",
                    ""
                ],
                [
                    "Cargo.lock",
                    "Cargo.lock",
                    "",
                    ""
                ],
                [
                    "Cargo.toml",
                    "Cargo.toml",
                    "",
                    ""
                ],
                [
                    "LICENSE",
                    "LICENSE",
                    "",
                    ""
                ],
                [
                    "README.md",
                    "README.md",
                    "",
                    ""
                ],
                [
                    "foundry.toml",
                    "foundry.toml",
                    "",
                    ""
                ],
                [
                    "funding.json",
                    "funding.json",
                    "",
                    ""
                ],
                [
                    "hardhat.config.ts",
                    "hardhat.config.ts",
                    "",
                    ""
                ],
                [
                    "index.ts",
                    "index.ts",
                    "",
                    ""
                ],
                [
                    "package.json",
                    "package.json",
                    "",
                    ""
                ],
                [
                    "rustfmt.toml",
                    "rustfmt.toml",
                    "",
                    ""
                ],
                [
                    "test-utils.ts",
                    "test-utils.ts",
                    "",
                    ""
                ],
                [
                    "tsconfig.json",
                    "tsconfig.json",
                    "",
                    ""
                ],
                [
                    "yarn.lock",
                    "yarn.lock",
                    "",
                    ""
                ],
                [
                    "View all files"
                ]
            ]
        ],
        "code_blocks": []
    },
    "https://blog.openzeppelin.com/uma-across-v2-audit/": {
        "title": "UMA Across V2 Audit - OpenZeppelin blog",
        "headers": [
            "UMA Across V2 Audit 2022",
            "Scope",
            "System Overview",
            "Privileged Roles",
            "Summary",
            "Critical Severity",
            "Slow relays on multiple chains",
            "Medium Severity",
            "Inconsistent signature checking",
            "Confusing removeLiquidity behavior could lock funds",
            "whitelistedRoutes for Ethereum_SpokePool affect other routes",
            "Low Severity",
            "chainId function is not virtual",
            "Lack of input validation",
            "No good way to disable routes in HubPool",
            "Polygon bridger does not enforce chainId requirements",
            "Liquidity provisioning can skew fee assessments",
            "Some functions not marked nonReentrant",
            "Unexpected proposal cancellation",
            "Time is cast unsafely",
            "Notes & Additional Information",
            "Missing link to referenced code",
            "Inconsistent approach to struct definitions",
            "Inconsistent token metadata versioning",
            "Lack of documentation",
            "Magic values",
            "Misleading Comments",
            "payable multicall function disallows msg.value",
            "Naming issues",
            "Warning about nonstandard tokens",
            "Not using immutable",
            "Residual privileged roles",
            "Typographical errors",
            "Undocumented implicit approval requirements",
            "Unused code",
            "Unnecessary import statements",
            "whitelistedRoute can be external",
            "Conclusions",
            "Update: Additional PRs reviewed",
            "Related Posts",
            "\n\n                                Forta Firewall Incremental Audit\n                              \n",
            "\n\n                                Origin OUSD Audit\n                              \n",
            "\n\n                                Sonic Gateway Audit\n                              \n"
        ],
        "paragraphs": [
            "Secure smart contract templates",
            "Interactive smart contract generator",
            "Safe and easy smart contract upgrades",
            "Send reliable transactions via API",
            "Gain visibility into your smart contracts",
            "Automate smart contract operations",
            "Manage contract roles and permissions",
            "Find and resolve smart contract vulnerabilities",
            "Launch and upgrade smart contracts safely",
            "Interactive transaction builder",
            "Industry standard for securing smart contracts",
            "React with expertise and speed",
            "Scalability, Privacy, and Security",
            "Developer acquisition, accelerated",
            " ",
            "The UMA Across system provides a mechanism that, in effect, allows users to send funds between all supported chains without waiting for standard token bridge transfers to complete. We audited the UMA Across V2 Protocol over the course of 2 weeks, with 2 auditors, plus another auditor for 1 week.",
            "The audited commit was bf03255cbd1db3045cd2fbf1580f24081f46b43a of the across-protocol/contracts-v2 repository.",
            "The contracts in scope were (in the /contracts/ directory):",
            "The Across V2 system manages multiple contracts which hold funds and transfer them to each other. These are the HubPool and multiple SpokePools. The Spokes can exist on other chains, and thus there are standardized “adapters” for sending funds from the hub to the various spokes in order to have a predictable interface.",
            "The system allows users to make deposits on one chain, specifying a desire to withdraw on a different chain and paying a fee. At any point, other users can “fill” this “relay”, supplying the original depositor with funds on a different chain and taking a small fee. The relayers are then refunded by the system. If relayers do not fill deposits, the system performs a “slow relay” in which funds are moved across cross-chain bridges to fill the deposit.",
            "The system cannot easily pass messages across cross-chain bridges, so in order for the hub to understand the state of all spokes, and to transfer funds accordingly, merkle trees are produced representing the needed actions, such as rebalances and relayer refunds. These merkle trees are represented with their roots, where the full set of needed merkle roots is called the “root bundle”. These are optimistically validated – meaning that they are considered truthful if not disputed within a certain time window. Once the liveness period (in which other users can dispute a root bundle) passes, funds can be transferred between the hub and spokes by using merkle proofs to prove that the transfer was included in the root bundle.",
            "The rules by which a root bundle is determined invalid are notably NOT a part of the smart contract system, and are instead decided by an outside system called the Optimistic Oracle. These dispute rules are to be codified into an UMIP (UMA Improvement Proposal) or multiple UMIPs. Therefore, much of the security of the system rests on the un-audited UMIP, and for the sake of the audit we treated the UMIP as a black box. During the audit, we provided the UMA team with suggestions and reminders for important security considerations when it comes to codifying the UMIP(s).",
            "There is one admin for the whole system. This admin can make decisions regarding which chains have valid spokes, which tokens are enabled, and which tokens on some chain map to which tokens on some other chain. The admin also controls parameters such as the system fee percentage, where fees are directed, what the bond for proposing new root bundles is, how disputed root bundles are identified, and which tokens are allowed within the system. This role is intended to eventually be set to the UMA Governor contract (controlled by UMA token holders).",
            "The Optimistic Oracle, which is controlled by UMA holders, has the ability to resolve disputes on root bundles. This means that if it is compromised, it is possible for disputes to not resolve correctly, and, more importantly, whoever can control the optimistic oracle can decide how funds are moved within the system. This is notably a feature of the greater UMA ecosystem, and incentives exist to keep the Optimistic Oracle honest.",
            "As stated, many of the security properties of the system could not be evaluated as they are affected by UMIPs which are not contained in the scope of this audit. Much of the audit involved checking integrations with cross-chain bridges, and many of the findings in the audit arose from these. Many of the problems identified had to do with problems inherent to synchronising information across multiple chains. More serious issues arose from improper use of signature schemes and insufficient information being passed to distinguish information needed for a single chain when not on that chain.",
            "Overall, we were impressed with the thoughtfulness and attention to edge cases that the UMA team apparently had when developing the protocol. We were also deeply appreciative of their responsiveness when it came to understanding the intent of certain parts of the protocol, and for elucidating the planned UMIP schema for validating root bundles. We appreciated their willingness to collaborate to find solutions and provide documentation to better explain the intent of the codebase.",
            "The UMIP is an extremely crucial part of the system, and if designed poorly creates opportunities for loss of funds in the protocol. The UMIP will need to include robust dispute resolution mechanisms and encompass many different reasons for dispute. Once again, the UMIP was not audited as part of this engagement, though we did provide feedback where applicable to address security concerns that should be addressed by the UMIP.",
            "Finally, there was an issue related to griefing which were identified as an unfortunate byproduct of the system design. The system intentionally does not “earmark” funds for any specific recipient, instead performing rebalances between spokes and allowing authorized users to pull funds from these spokes. Thus, there are potential issues in which a user would have to wait much longer than expected for their funds if the funds are routinely taken by other users before them. However, there is little advantage for an attacker to grief this way, as they pay a small fee to create a valid deposit each time they do. Additionally, this attack goes down in likelihood as liquidity for the specific token increases, as relays for tokens with high liquidity will typically be filled by relayers (instead of system funds) who can earn a profit by doing so. The result is that such greifing is really only a problem for extremely illiquid and centrally held tokens, which may simply not be allowed in the system.",
            "In each root bundle, the slowRelayRoot represents all the slow relays in a batch, which could involve multiple tokens and spoke pools. A valid root bundle would ensure the poolRebalanceRoot has a leaf for every spoke chain. When this rebalance leaf is processed, the slowRelayRoot will also be sent to the corresponding spoke pool.",
            "Notably, every spoke pool receives the same slowRelayRoot, which represents all slow relays in the batch across the whole system. When the slow relay is executed, the Spoke Pool does not filter on the destination chain id, which means that any slow relay can be executed on any spoke chain where the Spoke Pool has sufficient funds in the destinationToken. Consider including the destination chain ID in the slow relay details so the Spoke Pool can filter out relays that are intended for other chains.",
            "Update: Fixed in pull request #79 as of commit 2a41086f0d61caf0be8c2f3d1cdaf96e4f67f718.",
            "Depositors can update the relay fee associated with their transfer by signing a message describing this intention. The message is verified on the origin chain before emitting the event that notifies relayers, and verified again on the destination chain before the new fee can be used to fill the relay. If the depositor used a static ECDSA signature and both chains support the ecrecover opcode, both verifications should be identical. However, verification uses the OpenZeppelin Signature Checker library, which also supports EIP-1271 validation for smart contracts. If the smart contract validation behaves differently on the two chains, valid contract signatures may be rejected on the destination chain. A plausible example would be a multisignature wallet on the source chain that is not replicated on the destination chain.",
            "Instead of validating the signature on the destination chain, consider including the RequestedSpeedUpDeposit event in the off-chain UMIP specification, so that relayers that comply with the event would be reimbursed. This mitigation would need a mechanism to handle relayers that incorrectly fill relays with excessively large relayer fees, which would prevent the recipient from receiving their full payment. Alternatively, consider removing support for EIP-1271 validation and relying entirely on ECDSA signatures.",
            "Update: Fixed in pull request #79 as of commit 2a41086f0d61caf0be8c2f3d1cdaf96e4f67f718.",
            "When a relayer fills a relay, they specify a repaymentChainId to indicate which chain they want to be refunded on. However, the repaymentChainId is not validated against any set of acceptable values. Instead, it is included in the _emitFillRelay event, which is used for generating root bundles in the system.",
            "Since not all tokens may exist on all chains, and some chain ID’s may not exist or be a part of the Across V2 system, consider specifying valid values for repaymentChainId for a given token, and implementing logic similar to that for enabledDepositRoutes to use for checking repaymentChainId. Alternatively, consider specifying in the UMIP some procedures for root bundle proposers to determine whether a repaymentChainId is valid, and what to do if it is not. In this case, invalid repaymentChainIds may mean a repayment is simply not repaid – if this is chosen, ensure that this is made very clear in any documentation about the system, so that users are not surprised by losing funds.",
            "Update: Acknowledged. The UMA team intends to address this off-chain. They state:",
            "We believe that this issue can be resolved in a well-defined UMIP that lists valid repayment chain IDs (or points to where to find them), and provide a default repayment chain ID for invalid ones. For example, the UMIP could stipulate that any invalid repayment chain IDs are repaid on mainnet.",
            "The removeLiquidity function in the HubPool contract accepts a boolean argument sendEth. This should be set to true “if L1 token is WETH and user wants to receive ETH”.",
            "However, if the “user” is a smart contract, even if the L1 token is WETH and the sendEth argument is true, WETH, not ETH, will ultimately be sent back.",
            "This is the case because if sendEth is true, then the _unwrapWETHTo function is called. That function checks if the intended recipient is a smart contract, and, if so, sends WETH.",
            "If the receiving smart contract has no mechanism to handle WETH and was only expecting ETH in return, as was explicitly specified by the sendEth argument submitted, then any WETH sent to such a contract could become inaccessible.",
            "To avoid unnecessary confusion and the potential loss of funds, consider either reverting if a smart contract calls removeLiquidity with the sendEth argument set to true or modifying the _unwrapWETHTo function so that it can also be provided with and abide by an explicit sendEth argument.",
            "Update: Fixed in pull request #90 as of commit a1d1269e8a65e2b08c95c261de3d074abc57444d and pull request #139 as of commit f4f87583a4af71607bacf7292fee1ffa8fc2c81d.",
            "When in HubPool‘s executeRootBundle function, tokens are moved between spokes in order to complete rebalances of the different spoke pools. These token transfers happen within the _sendTokensToChainAndUpdatePooledTokenTrackers function, but in order to complete a rebalance the route from the chainId of the HubPool to the destination chain must be whitelisted.",
            "The issue comes from the conflation of two slightly different requirements. When whitelisting a route, a combination of origin chain, destination chain, and origin token are whitelisted. However, when rebalancing tokens, the specific route where origin chain is the HubPool‘s chain must be whitelisted for that token and destination chain pairing.",
            "This means that if other routes are to be enabled for rebalancing, the route from the Ethereum_SpokePool to some destination chain’s SpokePool must be enabled as well. This may allow undesired transfers to the Ethereum_SpokePool. Additionally, it may cause problems if some token is to be allowed to move between chains aside from Ethereum, but specifically not Ethereum. It would be impossible to disable transfers to the Ethereum_SpokePool without also disabling transfers between separate spoke pools for the same token.",
            "Also note that whitelisting a route does not necessarily whitelist the route from Ethereum to the same destination chain. This means that a separate transaction may need to be sent to enable rebalances to/from that destination, by whitelisting the Ethereum-as-origin route. This is confusing and could lead to unexpected reversions if forgotten about.",
            "Consider modifying the whitelist scheme so that rebalances to specific chains are automatically enabled when enabling certain routes. For example, if the route for some token to move from Arbitrum to Optimism is enabled, then the route from the Hub to Optimism should also be enabled. Additionally, consider implementing some special logic to differentiate routes from the HubPool and routes from the Ethereum_SpokePool, so that either route can be enabled independently of the other.",
            "Update: Fixed in pull request #89 as of commit 2d0adf78647070e4dd20690f67f46daaa6fc82c4.",
            "Within SpokePool.sol, the function chainId is marked override. However, the comments above it indicate that the function should also be overridable, meaning that it should be marked virtual.",
            "Consider marking the function virtual to allow overriding in contracts that inherit SpokePool.",
            "Update: Fixed in pull request #82 as of commit cc48e5721ea444a22a84ddeeef8dcbfe191b112c.",
            "Throughout the codebase there are functions lacking sufficient input validation. For instance:",
            "To avoid errors and unexpected system behavior, consider implementing require statements to validate all user-controlled input, even that of admin accounts considering that some clients may default to sending null parameters if none are specified.",
            "Update: Fixed with pull request #113 as of commit 4c4928866149dcec5bd6008c5ac8050f30898b7f and pull request #142 as of commit 2b5cbc520415f4a2b16903504a29a9992a63d41c.",
            "Within the SpokePool there exists the enabledDepositRoutes mapping, which lists routes that have been approved for deposits (allowing a user to deposit in one spoke pool and withdraw the deposit from another). The setEnableRoute function can be used to enable or disable these routes.",
            "Within the HubPool, there is a separate whitelistedRoutes mapping, which determines whether tokens can be sent to a certain spoke during rebalances. The only way to affect the whitelistedRoutes mapping is by calling whitelistRoute, which includes a call to enable the originToken/destinationChainId pair within the Spoke. This means that there is no good way to disable a whitelisted route in the hub without “enabling” the same route in the enabledDepositRoutes mapping in the SpokePool.",
            "Assuming that there may be cases in the future where it would be desirable to disable a certain deposit route, consider adding a function which can disable a whitelistedRoutes element (by setting the value in the mapping to address(0)) without enabling the route in the SpokePool. It may be desirable to disable both atomically from the HubPool, or to establish a procedure to disable them independently in a specific order. Consider designing a procedure for valid cross-chain token transfers in the case that only one mapping has a certain route marked as “disabled”, and including this in the UMIP for dispute resolution. Finally, note that any “atomic” cancellations will still include a delay between when the message is initiated on the hub chain and when execution can be considered finalized on the spoke chain.",
            "Update: Fixed in pull request #89 as of commit 2d0adf78647070e4dd20690f67f46daaa6fc82c4.",
            "The PolygonTokenBridger contract’s primary functions are only intended to be called either on l1 or l2, but not both. In fact, calling the functions on the wrong chain could result in unexpected behavior and unnecessary confusion.",
            "In the best case, the functions will simply revert if called from the wrong chain because they will attempt to interact with other contracts that do not exist on that chain. For example, calling the receive function (by sending the contract some native asset) could trigger reverts on Polygon, but not on Ethereum, because there is a WETH contract at the l1Weth address on the latter but not the former.",
            "However, in the worst case, it is possible that such calls will not revert, but result in lost funds instead. For example, if a WETH-like contract was later deployed to the l1Weth address on Polygon, then the call would not revert. Instead, tokens would be sent to that contract and could remain stuck there.",
            "Although the inline documentation details which function should be called on which chain, consider having the functions in this contract actively enforce these requirements via limiting execution to the correct block.chainid.",
            "Update: Fixed in pull request #115 as of commit b80d7a5396d31662265bb28b61a1a3d09ed76760 and pull request #128 as of commit 811ac20674d28189fd01297c05ce5b9e89f7a183.",
            "In the HubPool contract the enableL1TokenForLiquidityProvision function allows the contract owner to enable an l1token to be added to the protocol for liquidity pooling.",
            "This is allowed even if the l1token is already currently enabled.",
            "As this function also sets the lastLpFeeUpdate variable to the then-current block.timestamp, enabling an already enabled token will skip over the period of time since lastLpFeeUpdate was last set. As a result, any LP fees that should have been assessed for that time period would simply never be assessed.",
            "Consider reverting if this function is called for an l1token that is already enabled.",
            "Update: Fixed in pull request #94 as of commit b1a097748a82c3276619a06fa36358b574f843e1.",
            "We have not identified any security issues relating to reentrancy. However, out of an abundance of caution, consider marking the following public functions in the HubPool contract as nonReentrant. Consider that the nonReentrant modifier only works if both the original function, and the re-entered function are marked nonReentrant.",
            "Update: Fixed. Partially addressed in pull request #62 as of commit a3b5b5600e53d2ae877a4c1c18d78aadb01ff2e6 and then fully addressed in pull request #92 as of commit 7aa2fa8f46f8d40512857f35dd3ac64587c61f18.",
            "In the HubPool contract during a call to the disputeRootBundle function, if the bondAmount and finalFee values are the same, then the proposer bond passed to the optimistic oracle is zero.",
            "When this happens, the optimistic oracle unilaterally sets the bond to the finalFee and then attempts to withdraw bond + final fee.",
            "Since the HubPool only sets the allowance for the oracle to bondAmount rather than bondAmount + finalFee, this transfer will fail and, as a result, the proposal will be cancelled.",
            "This means that in the situation where bondAmount and finalFee values are identical, every proposal will be cancelled. Consider documenting this situation, checking for it explicitly and reverting with an insightful error message. Additionally, consider trying to avoid the situation by reverting in the setBond function if the newBondAmount is equal to the finalFee or in the proposeRootBundle function if bondAmount is equal to the finalFee.",
            "Update: Partially fixed in pull request #96 as of commit 671d416db0fe6d813e3761bda0e3132cb30a8e1d. The condition is checked in setBond but not in proposeRootBundle.",
            "In the HubPool function _updateAccumulatedLpFees, the return value of getCurrentTime() is cast to a uint32 value. This means that the value will be truncated to fit within 32 bits, and at some point around Feb 6, 2106, it will “roll over” and the value returned by casting to uint32 will drop down to 0. This will set pooledToken.lastLpFeeUpdate to a much lower number than the previous lastLpFeeUpdate. Any subsequent time _getAccumulatedFees is called, the timeFromLastInteraction calculation will be exceedingly high, and all “undistributed” fees will be accounted for as accumulated.",
            "Again, note that this issue will only occur starting in the year 2106. Consider changing the size of the cast from uint32 to a larger number, like uint64. This should be more than enough to not encounter limits within a reasonably distant future. Alternatively, consider documenting the behavior and defining a procedure for what to do if the system is still in operation when the uint32 limit is hit, or for shutting down the system before the year 2106.",
            "Update: Fixed in pull request #95 as of commit 2f59388906346780e729f2b879b643941ea314c9.",
            "Within the Ethereum_Adapter, there is a mention of copying code from “Governor.sol”. It appears that the contract in question is Governor.sol from the UMAprotocol/protocol repository.",
            "Since it is a part of a separate repository, and it is possible that the code may change in the future, consider including a link to the file, including a commit hash, so that it can be easily referenced by developers and reviewers in the future.",
            "Update: Fixed in pull request #97 as of commit ac9ed389914dc4249f488226fcd94d6d0b44aeb0.",
            "The PoolRebalanceLeaf struct is defined in HubPoolInterface.sol, while the RootBundle, PooledToken, and CrossChainContract structs are all defined in the implementation, HubPool.sol.",
            "Consider defining all structs for HubPool within the same contract.",
            "Update: Fixed in pull request #100 as of commit 9a98ce1ae5c8c5e95bcfa979666b980008d14d3f.",
            "In the LpTokenFactory contract, the LP tokens it creates have inconsistent versioning in their metadata.",
            "While the token symbol is prepended with Av2 (ostensibly for “Across version 2”), the token name is prepended only with “Across” and no version number.",
            "Consider adding the version number to the token name, or, alteratively, leaving an inline comment explaining the decision to omit the version number.",
            "Update: Fixed in pull request #101 as of commit 91a08a9bd2b47a1a1319aff8bda53349e8264ce3.",
            "Although most of the codebase is thoroughly documented, there are a few instances where documentation is lacking. For instance:",
            "To further clarify intent and improve overall code readability, consider adding additional inline documentation where indicated above.",
            "Update: Fixed in pull request #102 as of commit e2bfe128ff1a9aeed02bfcebe58a5880ad283698.",
            "In the LpTokenFactory contract, when the createLpToken function is called, it creates a new ERC20 LP token and adds the msg.sender to the new token’s minter and burner roles. These role assignments use the magic values 1 and 2, which are the uint identifiers for the respective roles.",
            "Rather than using these literal values to assign roles, consider using the the ExpandedERC20.addMinter and ExpandedERC20.addBurner functions.",
            "Update: Fixed in pull request #103 as of commit e9d3419ac6eb609b0c9165cdeac3fbff58285d18.",
            "Consider correcting these comments to make the code easier to understand for reviewers and future developers.",
            "Update: Fixed in pull request #109 as of commit 21cdccd5cbfffd4f120ab56c2691b8e961a8d323, pull request #104 as of commit 1148796377365a2de52fb89810f769ffb7f8c96f and pull request #138 as of commit c0b6d4841b86ba8acf3e4a3042a78a1307410e6a.",
            "The MultiCaller contract is inherited by the HubPool and SpokePool contracts. It provides the public multiCall function that facilitates calling multiple methods within the same contract with only a single call.",
            "However, although it is designated as a payable function, it disallows any calls that send ETH, ie where msg.value is not zero.",
            "This effectively makes the payable designation moot and the contradictory indications could lead to confusion.",
            "In the context of the HubPool, specifically, relays destined for chains where ETH is required and where a call to loadEthForL2Calls is therefore necessary, will not be multi-callable.",
            "Consider either explicitly noting this limitation, or removing both the require statement and the payable designation.",
            "Update: Fixed in pull request #98 as of commit 7092b8af1da15306994ea760b9669a9bd1f776c1.",
            "We have identified some areas of the code which could benefit from better naming:",
            "Consider following our renaming suggestions to make the codebase easier for developers and reviewers to understand.",
            "Update: Fixed in pull request #105 as of commit 87b69cdf159a1db5ccfcaa9f27825dfa416e7158.",
            "Although tokens must be enabled to be used in the system, it is important to define what may make a token troublesome so that which tokens can be whitelisted is easier to determine.",
            "Consider documenting procedures for tokens which behave unexpectedly to be filtered for before whitelisting.",
            "Update: Fixed in pull request #137 as of commit ba6e03974cf722d33b9fb2def4da578129f5baed.",
            "Within the HubPool contract, the weth, finder, and lpTokenFactory variables are only ever assigned a value in the constructor.",
            "Consider marking these values as immutable to better signal the fact that these values or not meant to change and to reduce the overall gas consumption of the contract.",
            "Update: Fixed in pull request #108 as of commit cccb9556345edcc5d8fc3022ab64a5b368c8d810.",
            "When the LpTokenFactory contract creates an ExpandedERC20 token contract, the factory becomes the owner of that token contract. The factory then proceeds to assign the minter and burner roles to the msg.sender. The factory remains the owner.",
            "As this is a residual power that is no longer needed by the LpTokenFactory, consider reducing the number of addresses with privileged roles by transferring ownership to the msg.sender.",
            "Update: Fixed in pull request #109 as of commit 21cdccd5cbfffd4f120ab56c2691b8e961a8d323.",
            "In HubPool.sol:",
            "In HubPoolInterface.sol:",
            "In MerkleLib.sol:",
            "In Polygon_SpokePool.sol:",
            "In SpokePool.sol:",
            "In SpokePoolInterface.sol:",
            "Update: Fixed in pull request #110 as of commit 813cfeef126484e0ac5b7fb91225560c5edbff7c.",
            "Throughout the codebase, when the safeTransferFrom function is used to transfer assets into the system from an external address there is an implicit requirement that the external address has already granted the appropriate approvals.",
            "For instance:",
            "In favor of explicitness and to improve the overall clarity of the codebase, consider documenting all approval requirements in the relevant functions’ inline documentation.",
            "Update: Fixed in pull request #111 as of commit 5a3ef77a22b81411a3616bb48acf063acabb4d2c.",
            "Throughout the codebase, there are instances of unused code. For example:",
            "Update: Fixed in pull request #78 as of commit f7e8518050a12e478516da6622bcf2357bb2e802 and in pull request #99 as of commit d89b1fb8d491703ef63dae0b29d93abd29d501de.",
            "The below list outlines contract import statements that are unnecessary:",
            "Consider removing unnecessary import statements to simplify the codebase and increase overall readability.",
            "Update: Fixed in pull request #112 as of commit d81295d3fd433a1f08fdd42c75a0aa3233a77dbe.",
            "The whitelistedRoute function within HubPool is marked as public. However, it is not called anywhere within the codebase.",
            "Consider restricting the function to external to reduce the surface for error and better reflect its intent.",
            "Update: Fixed in pull request #89 as of commit 2d0adf78647070e4dd20690f67f46daaa6fc82c4.",
            "One critical issue was found. Some changes were proposed to follow best practices and reduce the potential attack surface. The contracts are highly dependent on a well-structured UMIP which determines the behavior of the Optimistic Oracle.",
            "During the fix review process, the UMA team provided us with a list of additional pull requests for our review. We proceeded to review the following additional PRs related to the Across V2 codebase:",
            "We performed an incremental audit on the forta-network/forta-firewall-contracts repository between...",
            "We audited the OriginProtocol/origin-dollar repository at commit 4495130. Smart Contract Audit.",
            "We audited the Fantom-foundation/Bridge repository at commit 558465d. Smart Contract Audit."
        ],
        "lists": [
            "Smart Contract Security Audit\n\n\n\n\n\n\n\n\n\n\nEmergency Response\n\n\n\n\n\n\n\n\n\n\nZKP Practice\n\n\n\n\nSolutions\n\n\n\n\n\n\n\n\nEcosystem Stack",
            "Documentation\n\n\n\n\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\n\nForum\n\n\n\n\n\n\n\n\n\n\nEthernaut CTF",
            "About us\n\n\n\n\n\n\nCareers\n\n\n\n\n\n\nSecurity Center",
            "Arbitrum_SpokePool.sol\n\n\nEthereum_SpokePool.sol\n\n\nHubPool.sol\n\n\nHubPoolInterface.sol\n\n\nLockable.sol\n\n\nLPTokenFactory.sol\n\n\nMerkleLib.sol\n\n\nOptimism_SpokePool.sol\n\n\nPolygon_SpokePool.sol\n\n\nPolygonTokenBridger.sol\n\n\nSpokePool.sol\n\n\nSpokePoolInterface.sol\n\n\nchain-adapters/Arbitrum_Adapter.sol\n\n\nchain-adapters/Ethereum_Adapter.sol\n\n\nchain-adapters/Optimism_Adapter.sol\n\n\nchain-adapters/Polygon_Adapter.sol",
            "In the \nHubPool\n contract the various \nadmin functions\n will accept \n0\n values for inputs. This could result in the loss of funds and unexpected behaviors if null values are unintentionally provided.\n\n\nIn the \nHubPool\n contract the \nsetProtocolFeeCapture\n function does not use the \nnoActiveRequests\n modifier. This could allow the protocol fee to be increased even for liquidity providers that have already provided liquidity.\n\n\nIn the \nMerkleLib\n library the \nisClaimed1D\n function does not work as expected if an \nindex\n is greater than 255. In such a case, it will return \ntrue\n despite the fact that those values are not actually claimed.\n\n\nIn the \nSpokePool\n contract the \ndeposit\n function does not enforce the requirement suggested by the \ndeploymentTime\n comment\n which says that relays cannot have a quote time before \ndeploymentTime\n.\n\n\nIn the \nSpokePool\n contract the \nspeedUpDeposit\n function does not restrict the \nnewRelayerFeePct\n to be less than 50% like the \nregular deposit does\n. In practice, the \n_fillRelay\n function won’t accept a fee that is too high, but this should still be enforced within \nspeedUpDeposit\n.\n\n\nIn the \nPolygonTokenBridger\n contract the “normal” use case of \nsend\n involves the caller, \nPolygon_SpokePool\n, \nevaluating\n if the token it is sending is wrapped matic in order to set the \nisMatic\n flag appropriately. However, for any other caller, if they forget to set this flag while sending wrapped matic, then their tokens would be unwrapped but not sent anywhere. For more predictable behavior, consider checking for wrapped matic inline rather than relying on the \nisMatic\n argument.",
            "setProtocolFeeCapture\n\n\nsetBond\n\n\nsetLiveness\n\n\nsetIdentifier\n\n\nwhitelistRoute\n\n\nenableL1TokenForLiquidityProvision\n\n\ndisableL1TokenForLiquidityProvision\n\n\naddLiquidity",
            "In the \nHubPool\n contract the public \nunclaimedAccumulatedProtocolFees\n variable has no inline documentation.\n\n\nIn the \nHubPoolInterface\n contract the inline documentation accompanying \nPoolRebalanceLeaf.netSendAmounts\n, although lengthy, could benefit from additional clarification around the case of negative values. It could clarify further that in such cases the actual \nnetSendAmounts\n value is ignored, but it should match the \namountToReturn\n parameter in the \nRelayerRefundLeaf\n.\n\n\nMany of the functions in the \nMerkleLib\n library are missing NatSpec \n@return\n statements.",
            "HubPool\n lines 718-719\n explain that the \nwhitelistedRoute\n function\n returns whitelisted destination tokens, but does not mention that if the token is \nnot\n whitelisted then the function returns \naddress(0)\n.\n\n\nThe comments in the declaration of the \nPoolRebalanceLeaf\n struct\n appear to refer to a previous version of the struct, making them hard to follow. For example, \nline 17\n implies there are two arrays above it (there is only one), and \nline 31\n suggests there are multiple arrays below it (there is only one).\n\n\nA \ncomment about \nHubPool.executeRootBundle\n states that the function deletes the published root bundle, however it does not.\n\n\nWithin the \nLPTokenFactory\n contract\n, the comments on \nlines 24 and 25\n should say “msg.sender” or “the calling contract” rather than “this contract”.\n\n\nThe comments \nabove the \nlpFeeRatePerSecond\n variable suggest that LP fees are released linearly. In fact, they are released sublinearly, because the \n_getAccumulatedFees\n function uses a \nfraction of the \nundistributedLpFees\n (which decreases over time for any given loan), rather than the total funds on loan.\n\n\nThe comment in \nSpokePool\n above the definition of \nclaimedBitmap\n state that there are \n256x256 leaves per root\n. However, due to the \nindexing scheme in \nMerkleLib\n, there are a maximum of \n2^248\n different values of \nclaimedWordIndex\n, with \n256\n different \nclaimedBitIndexes\n. A more clear comment might explain that there are \n256x(2^248)\n leaves per root.",
            "In \nHubPoolInterface.liquidityUtilizationPostRelay\n, the parameter \ntoken\n should be renamed to \nl1Token\n to better match other functions in the interface, as well as the \nfunction’s implementation in \nHubPool\n.\n\n\nIn the \nRootBundle\n struct, \nrequestExpirationTimestamp\n should be renamed to better indicate that it ends the \n“challenge period”\n. Consider renaming it to \nChallengePeriodEndTimestamp\n or similar.\n\n\nThe \nRootBundleExecuted\n event\n in \nHubPool.sol\n only names \none of its array parameters\n in the plural form, but when the \nevent is emitted\n, all array parameters are named in the plural form. Consider changing the event definition so that all array parameters are pluralized.\n\n\nThe name of \nfunction whitelistedRoute\n is vague and does not indicate what it’s output will be. Consider renaming it to something like \ndestinationTokenFromRoute\n to better match \nthe return value\n.\n\n\nWhen \nweth\n is used in \nPolygon_SpokePool.sol\n, it \nrefers to wrapped MATIC\n. Consider renaming the \nweth\n variable in \nSpokePool.sol\n to \nwrapped_native_token\n to make it more generalizable. This will make \nPolygon_SpokePool\n less confusing and be more generalizeable for future SpokePools.\n\n\nThe \nexecuteSlowRelayRoot\n and \nexecuteRelayerRefundRoot\n functions\n are executing leaves and should be renamed accordingly.\n\n\nThe \nunclaimedPoolRebalanceLeafCount\n parameter\n of the \nProposeRootBundle\n event should be renamed to \npoolRebalanceLeafCount\n, since it’s always the total number of leaves in the tree.\n\n\nThe \nRootBundleCanceled\n event\n names the last parameter as \ndisputedAncillaryData\n, but the proposal is not necessarily disputed. It should just be \nancillaryData\n.\n\n\nThe \n_append\n function\n of the \nLpTokenFactory\n could be called \n_concatenate\n to better describe its functionality.\n\n\nThe \nonlyEnabledRoute\n modifier\n has a \ndestinationId\n parameter that should be \ndestinationChainId\n to match the rest of the code base.",
            "ERC20 tokens which charge fees, or which can charge fees, will result in various accounting issues as the amount \ntransferred\n will not match the amount received by the contracts in the system. Many spots in the code, such as \nin the \naddLiquidity\n function\n, assume the amount transferred in equals the amount received.\n\n\nERC777 tokens, which are ERC20-compatible, include hooks on transfers. These hooks are configurable and may be configured to revert in some or all cases. In \nSpokePool._executeRelayerRefundRoot\n, a failing transfer for one token could \nblock all other refunds\n for the specified leaf.\n\n\nTokens which are upgradeable may change their implementations to become subject to the above issues, even though they may not have been problematic before being upgraded.",
            "line 99\n: “Heler” should be “Helper”\n\n\nline 201\n: “proposal” should be “Proposal”\n\n\nline 235\n: “its” should be “it’s”\n\n\nline 294\n: “disputes..” should be “disputes.”\n\n\nline 377\n: “for again” should be “again.”\n\n\nline 419\n: “access more funds that” should be “to access more funds than”\n\n\nline 475\n: “to along” should be “along”\n\n\nline 480\n: “leafs” should be “leaves”\n\n\nline 532\n: “neccessary” should be “necessary”\n\n\nline 568\n: “to back” should be “back”\n\n\nline 569\n: “leafs” should be “leaves”\n\n\nline 569\n: “wont” should be “won’t”\n\n\nline 865\n: “timeFromLastInteraction ,undistributedLpFees)” should be “timeFromLastInteraction, undistributedLpFees)”\n\n\nline 866\n: “a fees.” should be “fees.”\n\n\nline 913\n: “decrease” should be “decreased”\n\n\nline 962\n: “send” should be “sent”",
            "line 13\n: “sent” should be “send”",
            "line 86\n: “\\*” should be “*”",
            "line 43\n: “priviledges” should be “privileges”",
            "line 55\n: “token” should be “chain”\n\n\nline 67\n: “leafs” should be “leaves”\n\n\nline 292\n: “users” should be “user’s”\n\n\nline 347\n: “receipient.” should be “recipient.”",
            "line 11\n: “inverted.” should be “negated.”\n\n\nline 27\n: “a the” should be “the”",
            "The \nproposeRootBundle\n function relies on \nsafeTransferFrom\n which requires that \nHubPool\n has been granted an allowance of \nbondAmount\n \nbondToken\ns by the caller.\n\n\nThe \naddLiquidity\n function relies on \nsafeTransferFrom\n, requiring that the \nHubPool\n has been granted an \nl1TokenAmount\n allowance of the caller’s \nl1Token\n.",
            "The \nproposerBondRepaid\n attribute of the \nHubPool\n contract’s \nRootBundle\n struct is never used. Consider removing it.\n\n\nThe \nevents\n in the \nArbitrum_Adapter\n contract are never used. As the relevant state variables are \nimmutable\n, consider setting \nall relevant values\n in the constructor and emitting these events then. Alternatively, consider adding comments indicating why events are declared but unused.\n\n\nThe \nL2GasLimitSet\n event\n in the \nOptimism_Adapter\n is never emitted. Consider emitting it in the constructor, removing it, or adding a comment indicating why it is declared but not used.\n\n\nThe \nHubPoolChanged\n event\n is never used.",
            "The \nWETH9\n and \nLockable\n imports are not used in the \nEthereum_Adapter\n contract.\n\n\nThe \nCrossDomainEnabled\n, \nIL1StandardBridge\n, and \nLockable\n imports are not used in the \nPolygon_Adapter\n contract.\n\n\nThe \nWETH9\n and \nIERC20\n imports are not used in the \nArbitrum_Adapter\n contract.\n\n\nThe \nAdapterInterface\n interface is \nimported twice\n in the \nArbitrum_Adapter\n contract.\n\n\nThe \nWETH9\n and \nSpokePoolInterface\n imports are not used in the \nEthereum_SpokePool\n contract.\n\n\nThe \nIERC20\n import in the \nLpTokenFactoryInterface\n interface is unused.\n\n\nThe \nMerkleLib\n is imported twice in the \nSpokePool\n contract.",
            "Pull request #78\n as of commit \nf7e8518050a12e478516da6622bcf2357bb2e802\n added “Emergency admin features to pause proposals and executions of root bundles, and to delete root bundles from the spoke pool to prevent a single bad bundle from permanently breaking or disabling the system.”\n\n\nA single security concern was noted: the Check-Effects-Interactions pattern was not being employed for the newly introduced \nemergencyDeleteProposal\n function. We raised that this is counter to best practice and could potentially, lead to issues later. This was then addressed later in \npull request #147\n as of commit \nee7714734aab4ed0457c813403a63e53c6438529\n.\n\n\nPull request #77\n as of commit \n8cf240a147b7d0467418eb81b2d6e152d478d101\n removes an extraneous fee. Specifically, it addresses the fact that the: “Slow relay charges 0 relayer fee % and refunds user this fee. The relayer fee is intended as a speed fee. The user shouldnâ€™t pay this fee for capital that the relayer doesnâ€™t loan them.”\n\n\nNo security concerns were noted.\n\n\nPull request #76\n as of commit \n70c56813e908cb5d02c43501d7de6a2c01564dca\n made changes to prevent a Spoke Pool’s address from accidentally/intentionally being set as \naddress(0)\n.\n\n\nNo security concerns were noted.\n\n\nPull request #64\n as of commit \n029406ec534da9979b63acf354e63394b4ce3a90\n changed the sizes of various \nuint\ns to better limit their range of values and to prevent them from holding values which are too high. This is related to issue \nL02\n.\n\n\nNo security concerns were noted.\n\n\nPull request #65\n as of commit \nd2ca5b2f1f604e30083a20c72f40d971c4161c59\n added a mapping to allow tokens on Optimism to be transferred across custom bridges rather than the standard bridge.\n\n\nNo security concerns were noted.\n\n\nOne suggestion to allow the blank \ndata\n field to be populated was made, but ultimately decided against.\n\n\nPull request #85\n as of commit \n248bb4d67dfb195b7077f8632f548fa3db808be5\n added logic to prevent redundant relays of root bundles to spoke pools on L2.\n\n\nNo security concerns were noted.\n\n\nPull request #120\n as of commit \na09e56b554577da8b929d8043fc6cdfb654e2ecf\n made changes to fix reversions when transferring tokens to Arbitrum.\n\n\nNo security concerns were noted.\n\n\nPull request #128\n as of commit \n811ac20674d28189fd01297c05ce5b9e89f7a183\n made changes to fix token bridging transactions using Polygon’s two bridge implementations.\n\n\nNo security concerns were noted.\n\n\nPull request #67\n as of commit \nac18f6a3fc89bc861af183a0b731c89837cf84ba\n modified parameter indexing for events.\n\n\nNo security concerns were noted.\n\n\nPull request #81\n as of commit \na72519e0965fc298ada2d19942ec5806530988df\n implemented argument spreading rather than passing \nPoolRebalanceLeaf\n objects when executing a root bundle “to improve etherscan tx processing.”\n\n\nNo security concerns were noted.\n\n\nPull request #84\n as of commit \n3ec3a7f990ee9a50a4a44f6baf893d38d2914b38\n removed \ngetRootBundleProposalAncillaryData\n functionality based on the fact that, even with the prior implementation of the function, off-chain information will still be required to dispute proposals.\n\n\nNo security concerns were noted.\n\n\nNoted that \nAncillaryData.sol\n is still being imported in \nHubPool.sol\n, though no longer used.\n\n\nPull request #114\n as of commit \n5a31be8aac645085f59e20cbb17e2fb24ec24f85\n removes the \ngetRootBundleProposalAncillaryData\n function altogether since it was just returning a literal empty string.\n\n\nNo security concerns were noted.\n\n\nPull request #116\n as of commit \n30ea0888b141c4085d7e30eab4beecd6c8fd9a62\n bumped the Solidity compiler version to the latest.\n\n\nNo security concerns were noted.\n\n\nPull request #73\n as of commit \n98237643f482d9333b394cbf3f2a2c075205b7ba\n made changes related to gas optimizations and storage packing.\n\n\nNo security concerns were noted.\n\n\nNoted unnecessary \nuint32\n usages in for loops that increased gas consumption and unnecessarily increased the possibility for overflow. This concern was subsequently addressed in \npull request #148\n as of commit \nf6d5bc387d24da6fc1cd99de10700d744daf3f6a\n.\n\n\nPull request #119\n as of commit \n709bf1d99e32e5a3bea7605c218020e9d6a1e1f5\n suppressed solhint warnings (in as limited a manner as possible).\n\n\nNo security concerns were noted.\n\n\nNoted a lack of spacing in some of the solhint suppression directives.",
            "Smart Contract Security Audit\n\n\nEmergency Response\n\n\nZKP Practice\n\n\nEcosystem Stack",
            "Documentation\n\n\nBlog\n\n\nForum\n\n\nEthernaut CTF",
            "About us\n\n\nCareers\n\n\nBrand Kit\n\n\nTrust"
        ],
        "tables": [],
        "code_blocks": []
    },
    "https://www.youtube.com/watch?v=iuxf6Crv8MI": {
        "title": "Internal Learning Session - Across V2 Architecture - YouTube",
        "headers": [],
        "paragraphs": [],
        "lists": [],
        "tables": [],
        "code_blocks": []
    },
    "https://docs.google.com/presentation/d/1aEq7t7yUfUAFTWug9PLdSDLdZCUJO4q7pGAoB24piZI/edit?usp=sharing": {
        "title": "Across V2 Internal Learning Session - Google Slides",
        "headers": [],
        "paragraphs": [],
        "lists": [],
        "tables": [],
        "code_blocks": []
    }
}